{"text": "Fun panel on open source AI that took place last week at the AI House in Davos.", "likes": "16", "reply": "Panel on Open Source in AI from the AI House at Davos with "}
{"text": "RIP Arno Penzias.\nHe was the head of Bell Labs' research organization, known as \"Area 11,\" when I joined in 1988.", "likes": "81", "reply": ""}
{"text": "It makes sense to cryptographically watermark *authentic* photos and videos.\nBut camera manufacturers, image processing software vendors, and distribution platforms have to agree on a standard.\n\nWatermarking AI-generated or heavily manipulated content may have some usefulness,…", "likes": "564", "reply": "Mandating watermarking of AI text is a magical thinking solution to a non-existent problem that will not work in reality.\n\nOpenAI gave up on theirs because it had 26% accuracy. \n\nHow good do you think your watermarking tech will be if the best OpenAI could come up with was 26%?…"}
{"text": "It's a joke, right?", "likes": "1K", "reply": "- Meta, by open sourcing competitive models (e.g., Llama 3) they reduce AI orgs' revenue/valuations/ability to buy more GPUs and scale AI models twitter.com/DanHendrycks/s…"}
{"text": "Yay, I'm a Marvel superhero!\nWhere's my Iron Man suit?", "likes": "391", "reply": "InstantID demo is now out on Spaces.\n\nThanks "}
{"text": "Very honored to have received the 2023 Global Swiss AI Award in Davos.\nThe ceremony took place in the Davos city hall in the presence of the mayor and involved me playing a kind of Swiss cowbell glockenspiel.", "likes": "763", "reply": ""}
{"text": "Global Swiss Award website: \nhttps://mindfire.global/global-swiss-ai-award…", "likes": "27", "reply": ""}
{"text": "Cowbells", "likes": "45", "reply": ""}
{"text": "In 1995, Patrick John Hayes established the Simon Newcomb Award for the silliest argument against the possibility of artificial intelligence.\n\nSimon Newcomb was the Canadian astronomer and mathematician who \"proved\" that manned heavier-than-air flight was impossible shortly…", "likes": "266", "reply": "I propose the creation of the DeTuring Award.\nIt will be granted to people who are consistently trying (and failing) to deter society from using computer technology by scaring everyone with imaginary risks.\nAs the Turing Award is the Nobel Prize of computing, the DeTuring Award…"}
{"text": "MIT Economist \n@amcafee\n explains why revolutions caused by new general purpose technologies (GPT), such as AI, do *not* cause mass unemployment.", "likes": "381", "reply": "@ylecun"}
{"text": "Welcome to FAIR, Taco!\nWe're thrilled to count you as a colleague.", "likes": "211", "reply": "Two weeks ago I joined Meta / FAIR, and I couldn't be more excited about this new chapter. Meta is indeed the only place left that supports highly ambitious long-term oriented & fundamental research projects and has a strong commitment to open science and open source. (and has… twitter.com/ylecun/status/…"}
{"text": "The \n@wef\n in Davos was intense and fruitful.", "likes": "471", "reply": ""}
{"text": "A great interview of Nick Clegg and me in El Païs about AI.\nWe discuss the limits of current technology, the necessity of building human-level AI assistants, and the regulation debates.", "likes": "158", "reply": ""}
{"text": "I propose the creation of the DeTuring Award.\nIt will be granted to people who are consistently trying (and failing) to deter society from using computer technology by scaring everyone with imaginary risks.\nAs the Turing Award is the Nobel Prize of computing, the DeTuring Award…", "likes": "", "reply": ""}
{"text": "Confused about the history of AI R&D at Meta?\nHere is the TL;DR", "likes": "314", "reply": "@nathanbenaich"}
{"text": "Confused about the recent announcement about FAIR?\nHere is the TL;DR: FAIR and GenAI are now sister-but-separate organizations under Chief Product Officer Chris Cox.", "likes": "65", "reply": "@giffmana"}
{"text": "Self-Rewarding LLMs.\nFrom FAIR+NYU.", "likes": "630", "reply": "New paper!"}
{"text": "AI could help with carbon capture.", "likes": "336", "reply": "Meta and "}
{"text": "Removing a space can make a phrase lose all its meaning, as in\n\"Open AI\" -> \"OpenAI\" \nand also as in\n \"Le Cun\" -> \"LeCun\" ", "likes": "559", "reply": "Zuck and Yann LeCunn will go down as heroes in human history!\n\nFighting for Open AI when the incumbents sought to shut it down!\n\nUnbelievable how much the vibes from Meta have changed over the last year. "}
{"text": "I have a simpler name for \"group attention\":  pooling.", "likes": "432", "reply": "The impressive in-context learning abilities of LLMs has created the need for larger context windows. Recently, researchers discovered that we can easily extend the context window of a pretrained LLM with one simple trick (and no extra training)…"}
{"text": "Precisely.\nThe general public often isn't aware that ideas don't just pop up out of the vacuum. \nIn a domain where people publish, there is often a long trail of interacting contributions, each of which plays a role.", "likes": "500", "reply": "Lot of people forget that just a few months prior to the Transformer, FAIR had the state of the art non recurrent machine translation model: ConvS2S. The highest order bit on the impact Transformers had was parallel forward and backward passes for training sequential models,… twitter.com/ylecun/status/…"}
{"text": "A big bunch of nails in the coffin of the idea that open source AI models are more dangerous than closed ones.\nAnd a huge warning to regulators who are on the way to throw the AI baby with the regulatory bath water.\n\nWhat has been happening since the release of Llama-2 is an…", "likes": "1K", "reply": ""}
{"text": "There is literally no other company doing this today: \n- open research towards human-level AI\n- open source AI platform enabling a huge AI ecosystem\n- wearable device to interact with always-on AI assistants", "likes": "2K", "reply": "Open Source AGI is an amazing vision. You are building a very powerful technology, and, actually aligning to what makes sense for the world: more people have a say in what makes sense and doesn't. Zuck and "}
{"text": "When something is viewed as a common software platform it has to be open source.", "likes": "884", "reply": "@wef"}
{"text": "A discussion between Karl Friston and me at the #WEF2024 in Davos.", "likes": "91", "reply": "@helloVERSES"}
{"text": "No open source AI ==> No AI startup ecosystem.", "likes": "842", "reply": "@ylecun"}
{"text": "FAIR's mission is to develop the science and technology for human-level AI assistants: machines that understand the world, can perceive, remember, reason, plan, and act.\n\nIn the not-to-distant future, all of our interactions with the digital world will be mediated by AI…", "likes": "1.5K", "reply": "Zuckerberg says Meta wants to build AGI and open source it, brings Meta's AI group FAIR closer to generative AI team; Meta will own 340K+ H100 GPUs by 2024 end ("}
{"text": "Better link.", "likes": "89", "reply": "Meta is all in on open source AGI, says Zuckerberg "}
{"text": "\"So, first of all, let me assert my firm belief that the only thing we have to fear is...fear itself — nameless, unreasoning, unjustified terror which paralyzes needed efforts to convert retreat into advance.\"\n-- Franklin D. Roosevelt.", "likes": "794", "reply": "Imagine if all the people creating the web browser and the early internet were constantly warning you that the internet would destroy the world instead of doing what it actually did, which is make the world more connected than ever before, while giving you access to all the…"}
{"text": "Avec \n@EmmanuelMacron\n à Davos.", "likes": "83", "reply": ""}
{"text": "Meta has always tried to do the Right Thing.\nMeta has always practiced open research in AI.\nMeta has been promoting open source AI platforms.\nAfter numerous discussions over the last year (sometimes contentious) a consensus is emerging that open source AI platforms are…", "likes": "1.7K", "reply": "@ylecun"}
{"text": "With \n@EmmanuelMacron\n in Davos.", "likes": "159", "reply": ""}
{"text": "A panel on AI at the \n@wef\n in Davos earlier today.\nWith \n@AndrewYNg\n, \n@DaphneKoller\n, @kaifulee, \n@aidangomez\n, and me, masterfully moderated by Nick Thompson from The Atlantic.", "likes": "463", "reply": "The Expanding Universe of Generative Models with "}
{"text": "To take Giant Steps you need a large learning rate.", "likes": "142", "reply": "What are the 20 most influential Atlantic Records jazz albums? A thread "}
{"text": "The Renaissance painting one at the bottom left is my favorite.", "likes": "614", "reply": "Create personalized stylish photo without LoRA training with "}
{"text": "Awesome text-to-{music,sound} system from FAIR.\nAnd yes, it's open source.", "likes": "847", "reply": "Happy to share MAGNeT "}
{"text": "I love this.\nThis is why open source AI platforms will win: it's the only way for AI to cater to highly diverse languages, cultures, values, and centers of interest.", "likes": "1.3K", "reply": "We release Kan-LLaMA [ಕನ್-LLama] — A 7B Llama-2 LoRA PreTrained and FineTuned on \"Kannada\" tokens"}
{"text": "Meta spends twice more on R&D than Amazon, Alphabet, and Microsoft, and 4 times more than Apple, when normalized by revenue.\nThe only other big tech that comes close is Nvidia.\nThat tells you a lot about who is building the technology of tomorrow.", "likes": "3.4K", "reply": "It is startling to see how much of the world's R&D spending comes from (mostly American) tech giants.\n\nThe R&D spending of Amazon is greater than the R&D spending of all companies and government in France. Alphabet beats Italy.\n\nPepsi's R&D spending beats all sources in Nigeria."}
{"text": "We need multiple AI assistants for the same reason we need multiple sources of news and information.\nWe need open source AI platforms for the same reason we need content-agnostic information distribution channels.\nDiversity.", "likes": "983", "reply": "Just checking in on alignment of LLMs in China, it's going about how you'd expect."}
{"text": "There are many good things and bad things about living in the US and living in France.\nDepending on your situation, profession, aspirations, and taste, you might prefer one or the other.\nPersonally, I like both and enjoy the best each has to offer ", "likes": "301", "reply": "@Appyg99"}
{"text": "Encoders are useful.", "likes": "670", "reply": "Generative large language models (LLMs) are based upon the decoder-only transformer architecture. Currently, these types of generative LLMs are incredibly popular. However, I use encoder-only architectures for 90% of use cases as a practitioner. Here’s why…"}
{"text": "Passion Dance by McCoy Tyner (piano), with Joe Henderson (tenor sax), Ron Carter (bass), Elaine Jones (drums).\nSooo much energy in McCoy and Joe's solos in this 1967 recording !\n\nhttps://youtu.be/0zdoOyeRTCA?si=2D8httj156CeZmDY…\n\nhttps://music.youtube.com/watch?v=0zdoOyeRTCA&si=G4T2ITJrwcGjdrSo…\n\nhttps://open.spotify.com/track/0lELi5BqmUO4hXTFfAUf60?si=3pOz1yr3QPe04twpO7Qu0A…", "likes": "86", "reply": ""}
{"text": "s/Elaine/Elvin/", "likes": "", "reply": ""}
{"text": "SeamlessExpressive from Meta-FAIR on HuggingFace: speech-to-speech translation that preserves the voice and the expression.", "likes": "155", "reply": "SeamlessExpressive enables high-quality speech translation that maintains the original speaker's vocal style, tone and unique expressions in translated outputs.\n\nMore documentation on our "}
{"text": "You know Elon, properly-run social networks do their best to take down misinformation about elections.", "likes": "3.2K", "reply": "1. "}
{"text": "Seriously, if you are a legal resident in the US, would you attempt to register to vote and risk losing your visa or green card and be deported, just so you can vote?\n\nIf you are an undocumented immigrant, would you attempt to register to vote and risk being thrown in jail and…", "likes": "", "reply": ""}
{"text": "Nice.\nThis used to be really, really hard.", "likes": "1.3K", "reply": "Announcing surya - a multilingual text line detection model for documents.  It gives you accurate line-level bboxes and column breaks.\n\nFind it here - "}
{"text": "Perceptual discrepancy.", "likes": "58", "reply": "A bit late to this, but YouGov polling matches a lot of what I've been saying. Most Americans say 2023 was great, good, or OK for them, but a majority say it was bad for the country — and the disparity is largely driven by Republicans"}
{"text": "Brains beat brawn.", "likes": "818", "reply": "it’s actually insane that a hacked together 8*30b model by like 5 cracked french guys is beating the billions poured into anthropic.\n\nhonestly very bearish on anthropic twitter.com/lmsysorg/statu…"}
{"text": "Good.", "likes": "60", "reply": "The latest Commission agenda (dated 7 January) confirms a Connectivity package on digital networks and infrastructure and the Initiative to open up European supercomputer capacity to AI start-ups on 21 February."}
{"text": "Very cool study comparing ConvNext and ViT architectures of similar sizes, trained in either supervised mode or with a CLIP-style method, and compared on a variety of properties.\n\nA collaboration between FAIR and MBZUAI.\nWeb page: https://kirill-vish.github.io/beyond-imagenet-accuracy/…", "likes": "472", "reply": "How to choose a vision model for your specific needs? \n\nHow do ConvNet / ViT, supervised / CLIP models compare with each other on metrics beyond ImageNet?\n\nOur work comprehensively compares common vision models on \"non-standard\" metrics. (1/n)"}
{"text": "Audiobox demo: audio generation from voice and text prompts.", "likes": "192", "reply": "You can now try Audiobox, our new foundation research model for audio generation that can generate audio using a combination of voice inputs and natural language text prompts.\n\nTry the demo "}
{"text": "Modems use an adaptive linear classifiers to turn analog signals into bit strings. It's called an \"adaptive equalizer\"\nIt is trained in two phases. The first one is supervised, the second one is self-supervised: \n1. In the initial phase, when the modem first connects to another…", "likes": "1.3K", "reply": "Did you know that some of the sounds old modems made when connecting (those  'bipppppp' tones) were actually due to them using a self-supervised learning method for adaptation? "}
{"text": "The speed at which a technology disseminates in the economy is limited by how fast people learn to use it.", "likes": "573", "reply": "Technology maturity isn’t sufficient to drive adoption\n\nInsightful analysis of the rise of tractors in US farms, put in parallel with Generative AI, by "}
{"text": "This is inspired by \n@erikbryn\n's work on the effect of technological revolutions on the labor market. It takes 15 to 20 years for technology revolutions to have a measurable impact on productivity because that's how long it takes for people to learn the new skills. I'm not sure…", "likes": "", "reply": ""}
{"text": "- AI techies: oh look, we can translate hundreds of languages automatically. This can lower linguistic barriers and connect humanity.\n- AI negativists: \"This is the world we're creating.  Removing the humanity from how we learn to connect with humanity.\"", "likes": "", "reply": ""}
{"text": "In case you are wondering, this is an actual quote from a tweet. I didn't retweeted that tweet because I don't want to turn this general comment into a personal attack.", "likes": "", "reply": ""}
{"text": "Monk.", "likes": "145", "reply": "You can only choose one. Who’s your go-to jazz composer?\n\nThelonious Monk | Miles Davis\nCharles Mingus | Duke Ellington"}
{"text": "Miles is a close second. Wins on diversity.", "likes": "", "reply": ""}
{"text": "Venture capital firm Andreessen-Horowitz \n@a16z\n wrote a letter to the UK House of Lords in defense of open source AI platforms.", "likes": "1K", "reply": ""}
{"text": "A few reasons why Auto-Regressive LLMs are very helpful for coding, even though they really can't plan.", "likes": "316", "reply": "Doesn't the fact that LLMs can \"write code\" prove that they can also reason and plan?  (Hint: Nope..) "}
{"text": "One reason AI research has been progressing so fast is not just because of frequent and early publication of preprint on ArXiv and the exchange of open source code, but also because the ML/AI community has largely freed itself from the stranglehold of for-profit & paywalled…", "likes": "2.6K", "reply": "@pmarca"}
{"text": "Hehe", "likes": "486", "reply": "Which big tech will be leading open-source AI in 2024?"}
{"text": "Paris AI is on fire.", "likes": "1.2K", "reply": "The ML ecosystem in France is on fire"}
{"text": "Here is a list of inexcusable mistakes in slide design:\n- not using all the space: showing a diagram or figure that does not fill as much space as possible on your slide. It's very frustrating for the audience to have to squint when there is ample unused space around a figure. \n-…", "likes": "577", "reply": "@shimon8282"}
{"text": "Reward densification.", "likes": "91", "reply": "@sainingxie"}
{"text": "Congrats \n@lxbrun\n, \n@braizh\n, \n@delphinegroll\n and the whole \n@nabla_ai\n team.", "likes": "253", "reply": "Nabla raises another $24 million for its AI assistant for doctors "}
{"text": "Nabla's shift from ChatGPT to open source LLMs (Llama and/or Mistral) is a perfect example of why I think open source AI platforms will constitute the foundation of the AI ecosystem of vertical applications.", "likes": "", "reply": ""}
{"text": "Hey, \n@HachetteUS\n , \n@HachetteLivre\n , \n@GroupeLagardere\n , and \n@arnaudlagardere\n, drop the hatchet against \n@internetarchive\n.\nYou are on the wrong side of history.", "likes": "609", "reply": "Friend of the Court Briefs Filed in Internet Archive’s Appeal — Hundreds of librarians joined prominent library organizations & non-profits in filing amicus briefs in Hachette v. Internet Archive. Read why they believe our appeal should succeed: "}
{"text": "Congrats \n@denisyarats\n and \n@AravSrinivas\n !", "likes": "449", "reply": "We are happy to announce that we've raised $73.6 million in Series B funding led by IVP with participation from NVIDIA, NEA, Bessemer, Elad Gil, Jeff Bezos, Nat Friedman, Databricks, Tobi Lutke, Guillermo Rauch, Naval Ravikant, Balaji Srinivasan."}
{"text": "Why I turned down an offer for Director of Research at Google in January 2002.", "likes": "1.3K", "reply": "@giffmana"}
{"text": "In which we learn that:\n1. Academic books are at best \"books\" or merely \"written material\" just because their authors expect no remuneration.\n2. I distributed \"books\" for free after doing what I'm being accused of refusing to do: asking for permission from the owners. Still not…", "likes": "210", "reply": "This is not a story about “free books.” It’s a story about a narrow & specific modality for distribution of written materials for which the authors expected no remuneration. The suggestion it’s about “books” writ large is a disingenuous stop on the non-apology tour. twitter.com/ylecun/status/…"}
{"text": "Let me tell a story about free books.\n\nIn the mid 1990s, I started a project called DjVu at AT&T Labs.\nThe purpose was to devise a new image compression format so that printed documents could be scanned at high resolution and distributed efficiently over the newly expanding…", "likes": "", "reply": ""}
{"text": "Interesting side story: Volume zero of NIPS (1987) was published by the American Institute of Physics, which is a non-profit publisher.\nAIP had sold the rights to Springer, which is very much for profit. We contacted Springer USA and requested permission to scan and post the…", "likes": "", "reply": ""}
{"text": "It took less than 100 years from 1924.", "likes": "228", "reply": "@paulisci"}
{"text": "Only a small number of book authors make significant money from book sales.\nThis seems to suggest that most books should be freely available for download.\nThe lost revenue for authors would be small, and the benefits to society large by comparison.", "likes": "2.5K", "reply": "A survey of 5,699 published authors, found that in 2022, their median gross pre-tax income from their books was $2,000. \n\nYou can generate more revenue than that in less time by mowing lawns in your neighborhood. "}
{"text": "A lot of misunderstanding in the comments.\nI'm certainly not suggesting there should be a rule forcing authors to release their books for free or anything.\nI'm just making the point that many authors who are more motivated by intellectual impact than by a thousand bucks of income…", "likes": "", "reply": ""}
{"text": "A more detailed  explanation for those who still don't get the point.", "likes": "52", "reply": "@Rahll"}
{"text": "Soooo much misunderstanding of my tweet on book publishing!\nI had to write a long explanation (below).\n\nI'm guessing that a lot of negative reactions are caused by some assumption of ill intent on my part within the current debate about copyright and AI.\nBut this has absolutely…", "likes": "435", "reply": "@Rahll"}
{"text": "Happy Doom-Free New Year ", "likes": "", "reply": ""}
{"text": "[sorry for the hash code collision, \n@ID_AA_Carmack\n ]", "likes": "", "reply": ""}
{"text": "AI is not some sort of natural phenomenon that we have no control over.\n\nAI is being built by us, humans.\n\nHence, if you're scared of AI, what you are actually scared of are your fellow humans.\nYou probably have doubts about the ability of institutions to do the right things with…", "likes": "", "reply": ""}
{"text": "Better access to knowledge is ....\n... As bad as opium ", "likes": "243", "reply": "Free libraries as bad as free opium??! \n\n\"that makes the wholesale establishment of free public libraries almost as much a menace to the well-being of the country as would be the opening up of free saloons or opium joints\" - The Marion Daily Mirror, 1910 (full page scan below)"}
{"text": "Who knew that coffee destroyed the fabric of society ", "likes": "336", "reply": "Here's the story of another technology that faced massive backlash in its time that will sound very familiar to today's battles over "}
{"text": "Never mind the typewriter, what about P(doom | PowerPoint) ?\n\n\"We had 12.9 GB of slides on our network and I thought, 'What a huge waste of corporate productivity.' So we banned it. And we've had three unbelievable record-breaking fiscal quarters since. Now, I would argue that…", "likes": "680", "reply": "What is your typewriter P(doom) number?\n\n\"If the typewriter were abolished it would improve our thinking and lessen the threat of war.\" (1955)"}
{"text": "The one true American art form was once thought to destroy the fabric of society and corrupt the youth.", "likes": "198", "reply": "@PessimistsArc"}
{"text": "Lots of great advances in AI from Meta in 2023.", "likes": "707", "reply": "To close out 2023, here are 10 of the most interesting AI research advancements we shared on our feed this year —  and where you can find more details on the work."}
{"text": "I agree with these predictions about AI from \n@MartinSignoux\n .", "likes": "307", "reply": "What a year it's been for AI. \n\nAnticipating what's next sounds very perilous, but I'll give it a try. \n\nHere are eight AI predictions for 2024"}
{"text": "Genuine question about image generation:\nIf someone uses a generative AI tool to produce an image that is substantially similar to a copyrighted piece (a drawing, painting, movie screenshot, etc), who should be liable for copyright infringement?\nShould it be:\nA. the company…", "likes": "", "reply": ""}
{"text": "Interesting take.", "likes": "214", "reply": "If you want to understand why the Times case has a near zero probability of winning, then read this thread. \n\nThis fellow does a nice write up and he seems sincere in his belief that what he is saying about the suit is accurate and correct when in fact it's basically just a lot… twitter.com/jason_kint/sta…"}
{"text": "Awww thanks, \n@Dan_Jeffries1\n.\n\nI don't have much in common with Voltaire (sadly), but I like this citation of his:\n\"Le bonheur est souvent la seule chose qu'on puisse donner sans l'avoir et c'est en le donnant qu'on l'acquiert.\"\n\"Happiness is often the only thing one can give…", "likes": "534", "reply": "Yann has quickly become the Voltaire of AI.\n\nIt's amazing that we have someone with a big profile out there passionately talking real sense and clear thinking pragmatism, while chicken littles scream the sky is falling and advocate for massive centralized control regimes. "}
{"text": "René Barjavel foresaw our addiction to smartphones!", "likes": "646", "reply": "In 1947, French science fiction writer René Barjavel was asked for a prediction of the future. He imagined a future with cell phones-like portable TVs and electronic communication in the film La télévision, œil de demain"}
{"text": "How to do real-time speech-to-speech translation while minimizing the latency", "likes": "632", "reply": "SeamlessStreaming uses a learned read/write policy to enable delivery of fast & accurate translations even when faced with differences in language structure in many language pairs.\n\nDetails on Seamless "}
{"text": "A lot of things are getting better in the world.", "likes": "383", "reply": "A nice way to end the year with some data: 66 Good News Stories You Didn't Hear About in 2023 "}
{"text": "Happy Isaac Newton Birthday \nAlso, happy 76th Birthday to the transistor (actually, 76 years and 2 days).", "likes": "", "reply": ""}
{"text": "Punchline needs an update:\n\"Sure, easy image recognition with a ConvNet. Gimme PyTorch and a few hours.\"", "likes": "922", "reply": "What was jokingly called impossible just a few years ago, is now completely possible and available at the tips of our fingers now"}
{"text": "Good move, Poland.\nYou need nuclear badly.", "likes": "1.1K", "reply": ""}
{"text": "Answering by approximate retrieval or by understanding+reasoning are two ends of a spectrum.\nHumans are at various places on this spectrum, depending on the task, experience, and depth of understanding.\nWe see this in physics or math students: some will study very hard, do lots…", "likes": "1.4K", "reply": "Unfortunately , too few people understand the distinction between memorization and understanding. It's not some lofty question like \"does the system have an internal world model?\", it's a very pragmatic behavior distinction: \"is the system capable of broad generalization, or is… twitter.com/RichardMCNgo/s…"}
{"text": "Open source AI foundation models will wipe out closed and proprietary AI models for the same reason Wikipedia wiped out generalist commercial encyclopedia: crowd-sourced human contributions to open platforms can cater to a high diversity of interests, cultures, and languages.", "likes": "", "reply": ""}
{"text": "Dans les semaines précédents les négociations de L'AI Act à Bruxelles, une mystérieuse organisation a financé une campagne de propagande en faveur de régulations restreignant la R&D en IA.\nLeur but était de faire interdire l'IA open source au niveau européen. \nLa campagne était…", "likes": "282", "reply": " \n\nLes médias:"}
{"text": "The business reason why open source AI platforms will win.", "likes": "1K", "reply": "Open-source models will destroy ChatGPT and Gemini.\n\nThe story of open-source Large Language Models is the story of Linux. Windows and Mac won consumers, but Linux became the Internet's operating system.\n\nThe same will happen with ChatGPT, Gemini, and open-source models. Closed,…"}
{"text": "Okay, same article, bigger portrait.", "likes": "710", "reply": "At the end of a year dominated by news of AI "}
{"text": "A new family of antibiotics discovered with graph deep learning.", "likes": "4.9K", "reply": "Big "}
{"text": "The new compounds can kill methicillin-resistant Staphylococcus aureus (MRSA) which causes 10,000 deaths per year in the US.\n\nBlog post from MIT:", "likes": "346", "reply": ""}
{"text": "Winter is coming in quantum computing ?\n\n\"Meta’s head of AI research Yann LeCun recently made headlines after pouring cold water on the prospect of quantum computers making a meaningful contribution in the near future. Speaking at a media event celebrating the 10-year anniversary…", "likes": "", "reply": ""}
{"text": "An interview of me in Wired with the unequaled Steven Levy.\n\"How Not to Be Stupid About AI, With Yann LeCun\"\nIt’ll take over the world. It won’t subjugate humans. For Meta’s chief AI scientist, both things are true.\n\nExcerpts: \n\n- Steven Levy: In a recent talk, you said, “Machine…", "likes": "", "reply": ""}
{"text": "Congratulations Dr Zeming \n@ebetica\n Lin ", "likes": "112", "reply": "I defended my thesis! Big thanks to my committee "}
{"text": "Real-time , low-latency, speech-to-speech translation that preserves the voice and expression of the speaker.", "likes": "2.4K", "reply": "SeamlessStreaming is an AI translation model that can deliver state-of-the-art results on streaming translation with <2 seconds of latency. One core piece of our latest Seamless Communication research work by teams at FAIR.\n\nMore on this project "}
{"text": "If the practice of medicine could be learned purely from text, training physicians would not require years of residency.", "likes": "1K", "reply": "Pretty much everyone in my family is a medical doctor. I often hear there's great intuition in practicing medicine effectively -- a gut feeling about whether a patient is healthy, from many subtle signals. Like riding a bike, medicine won't be automated by AI trained on text."}
{"text": "Here ya go.", "likes": "470", "reply": "LeCun's idea that \"the good AI's can protect us from the bad AI's\" is actually one of our best bets for ensuring a good future imo\n\nIt is what Dan Hendrycks calls a \"Leviathan\", a collective of good AI's to prevent rogue AI's from acting poorly. It also means we need models to be…"}
{"text": "Tired: military-industrial complex.\nWired: national security-effective altruism complex.", "likes": "421", "reply": ""}
{"text": "And then there are people who are simultaneously pro and anti....", "likes": "221", "reply": "Pro-AI: "}
{"text": "Fun chatting with \n@EricTopol\n and \n@lxbrun\n about AI and healthcare.", "likes": "141", "reply": "@RamziJelassi"}
{"text": "AI and AR/VR/smart glasses are converging.\nA blog post by Meta CTO \n@boztank\n.\n\nhttps://about.fb.com/news/2023/12/metas-2023-progress-in-ai-and-mixed-reality/…", "likes": "61", "reply": "2023 was a wild year for technological progress. At Meta, our two biggest long-term bets on the technologies of the future both make great leaps forward but more excitingly, they began to converge. I wrote about it here: "}
{"text": "Exactly.", "likes": "552", "reply": "In AI, the ratio of attention on hypothetical, future, forms of harm to actual, current, realized forms of harm seems out of whack. \n\nMany of the hypothetical forms of harm, like AI \"taking over\", are based on highly questionable hypotheses about what technology that does not…"}
{"text": "The whole genesis, history, and inspirations for PyTorch, in which \n@soumithchintala\n demonstrates that the free exchange of ideas and code makes software progress faster.\n\nUnlike with technical papers, there is no default citation mechanism for code. But citing sources of…", "likes": "470", "reply": "PyTorch's design origins, its connection to Lua, its intertwined deep connection to JAX, its symbiotic connection to Chainer\n\nThe groundwork for PyTorch originally started in early 2016, online, among a band of Torch7's contributors. "}
{"text": "Not surprising.  But ouch!", "likes": "669", "reply": "Good work from "}
{"text": "Technologies that empower humans by increasing communication, knowledge, and effective intelligence always cause opposition from people, governments, or institutions who want control and fear other humans.\nThe arguments against open source AI today mirror older arguments against…", "likes": "1.5K", "reply": "@primalpoly"}
{"text": "The emergence of superhuman AI will not be an event. Progress is going to be progressive.\nIt will start with systems that can learn how the world works, like baby animals.\nThen we'll have machines that are objective driven and that satisfy guardrails.\nThen, we'll have machines…", "likes": "", "reply": ""}
{"text": "Nice segment on CBS about AI research for the 10th anniversary of Meta's Fundamental AI Research lab (FAIR): the necessity of open research, AI risks and benefits, the future, AI assistants and domestic robots.", "likes": "137", "reply": "Amid fears of an artificial intelligence \"arms race,\" some researchers are emphasizing open research. "}
{"text": "In-depth interview on CBS Saturday Morning with Brook Silva-Braga, where we discuss the present and future of AI, the benefits and the risks.\n(and why AI isn't going to kill us but will make all of us smarter)", "likes": "337", "reply": ""}
{"text": "We are hiring!", "likes": "373", "reply": "Just realized that the last 10 things, I was impressed by or worked with (projects, papers, frameworks) are all from "}
{"text": "You're welcome.", "likes": "440", "reply": "Meta is the best thing that has happened to AI "}
{"text": "Starting soon", "likes": "36", "reply": "This panel will be FUN! Starts in 20min - 3:45pm CST. Stop by or call-in (register to get zoom link) "}
{"text": "Testing on the training set.", "likes": "453", "reply": "Quick lesson in the dangers of data contamination. Years ago, I came up with an acronym for remembering the periods of the Paleozoic era — “Catastrophic Overthrow Started Different Colder Period”. I was curious if ChatGPT could guess what it stood for. 1/4"}
{"text": "Not sure what imaginary universe some AI folks live in.", "likes": "1.1K", "reply": "NEW: I spoke to "}
{"text": "Like or comment if you agree.", "likes": "1.3K", "reply": "@ylecun"}
{"text": "It would be a useful exercise to imagine where the AI industry would be today if AI research labs in industry had remained closed, had not open sourced their code, had patented everything and enforced their patents.\n\nImagine a world without PyTorch, and with enforced patents on…", "likes": "3K", "reply": "AI is nothing without open source, "}
{"text": "Gigantic", "likes": "1.2K", "reply": "Poster sessions "}
{"text": "Auto-Regressive LLMs have a role to play: turning abstract ideas into token sequences (words, actions, code...).\nBut abstract ideas should be elaborated through planning/reasoning in representation space.\nAR-LLMs go directly from prompt to answer, skipping the step of reasoning…", "likes": "1K", "reply": "i'm skeptical of "}
{"text": "Ego-Exo4d: a large dataset of videos of people doing stuff.", "likes": "733", "reply": "Together with the Ego4D consortium, today we're releasing Ego-Exo4D, the largest ever public dataset of its kind to support research on video learning & multimodal perception — including 1,400+ hours of videos of skilled human activities.\n\nDownload "}
{"text": "Meta party at #neurips2023 \nGiant selfie.", "likes": "619", "reply": ""}
{"text": "VICReging with Randall at NeurIPS.\n\nhttps://arxiv.org/abs/2303.00633", "likes": "212", "reply": ""}
{"text": "With Ravid and Ido in front of our NeurIPS poster \"reverse engineering Self-Supervised Learning\"\n\nhttps://arxiv.org/abs/2305.15614", "likes": "479", "reply": ""}
{"text": "Selfying with the NeurIPS crowd at the Meta booth.", "likes": "1.4K", "reply": ""}
{"text": "\"Between extinction and renaissance: what AI can do for us\"\nA fireside chat with my former Meta colleague Jerome Pesenti hosted by the Transatlantic Leaders Forum last month in New York.\n\nWe talk about AI, why current LLM suck (yet are useful), and what the next steps in AI might…", "likes": "", "reply": ""}
{"text": "EU AI Act: it's not over yet.\nRegulating foundation models is a bad idea that was added late in the text and rightfully fought against by Macron's government.", "likes": "1.1K", "reply": ""}
{"text": "If it were true that raw intelligence was sufficient for a human to want to dominate others and succeed at it, then Albert Einstein, Richard Feynman, Leonard Euler, Niels Abel, Kurt Gödel and other scientists would have been both rich and powerful, and they were neither.\n1.…", "likes": "", "reply": ""}
{"text": "Excellent NYT article about parisian AI unicorn Mistral, the effervescent AI ecosystem in Paris, the rapidly increasing strength of the open source AI community, the support of open source AI by Meta, and the opposition to it by Google and OpenAI.", "likes": "371", "reply": ""}
{"text": "Ways to get Auto-Regressive LLMs to produce correct answers almost all the time:\n- test on the training set.\n- write the answer in the prompt.", "likes": "", "reply": ""}
{"text": "NYU Courant Institute authors at #NeurIPS2023", "likes": "31", "reply": "Established in 1987 to advance research in artificial intelligence and machine learning, the 36th "}
{"text": "Open source AI models are on a path to overtake proprietary models.", "likes": "1.6K", "reply": "This is perhaps one of the most important charts on AI for 2024.\n\nIt was built by the amazing researcher team at "}
{"text": "Former AT&T colleagues at #NeurIPS 2002:\nFront row: Patrick Haffner, Corina Cortes, me, Larry Jackel.\nStanding: Chris Burges, Yoshua Bengio, Bernhard Schölkopf, Sara Solla, Isabelle Guyon.", "likes": "422", "reply": ""}
{"text": ".\n@clmt\n demonstrating his FPGA implementation of convolutional networks doing real-time image recognition at #NeurIPS 2010.\nYes, before ConvNets were cool, we had them running on FPGAs.", "likes": "423", "reply": ""}
{"text": "A picture of former AT&T colleagues at #NeurIPS 2006:\nLéon Bottou, Dan Lee, Michael Littman, Chris Burges, Patrice Simard, Larry Jackel, and me.", "likes": "333", "reply": ""}
{"text": "Je suis signataire de cette tribune.", "likes": "133", "reply": "Baisse des compétences en mathématiques et en sciences : « Nous lançons un appel pour que soit mise en œuvre une stratégie nationale ambitieuse » "}
{"text": "Audiobox!", "likes": "771", "reply": "Starting today you can try our new foundation research model for audio generation. The demo includes Zero shot TTS, Text to sound effects, Infilling and more!\n\nTry Audiobox "}
{"text": "Thank you.", "likes": "889", "reply": "In my humble opinion, among all the big names of "}
{"text": "\"La société face aux défis de l'intelligence artificielle\"\nUn débat public organisé par la revue européenne Le Grand Continent hébergé à l'ENS.\n\nParticipants: Anne Bouverot, Marc Mézard, Martin Tisné, Jamal Atif, et moi-même.\n\nCe débat s'inscrit dans la continuité de l'entretien…", "likes": "", "reply": ""}
{"text": "What is good and not-so-good about the EU AI Act from \n@togelius", "likes": "161", "reply": "At least from this press release, it seems that the EU AI Act came out less bad than feared. We seem to have avoided any need for licensing or similar for foundation models, and open-source distribution is permitted and seemingly even encouraged."}
{"text": "The EU AI Act negotiations ended.\nOne contentious issue was the regulation of foundation models, particularly open source ones.\n\nKudos to the French, German, and Italian governments for not giving up on open source models.\n\nJuicy part: \n\"The legislation ultimately included…", "likes": "", "reply": ""}
{"text": "Purple Llama.", "likes": "256", "reply": "Announcing Purple Llama — A new project to help level the playing field for building safe & responsible generative AI experiences.\n\nPurple Llama includes permissively licensed tools, evals & models to enable both research & commercial use.\n\nMore details "}
{"text": "Telling all the Llama-2 things!", "likes": "151", "reply": "This talk by Angela Fan on Llama2 is so good. 30 min, she just tells you all the things."}
{"text": "With \n@jpineau1\n on the Boz To The Future podcast for the 10th anniversary of FAIR.", "likes": "40", "reply": "New episode of my podcast out today with AI luminaries "}
{"text": "Today, I was made a Chevalier de la Légion d'Honneur by President Macron at the Élysée Palace.\n\nPrésident Macron gave a wonderful speech.", "likes": "5.5K", "reply": ""}
{"text": "Nah, that's merely what the overly optimistic young guns, AGI startup fund raisers, and self-deluded technologists.\nFor most \"serious\" folks, the correct statement is:\n\"Human-level AI is always 10-20 years away\"", "likes": "1.4K", "reply": "AGI is always 3-5 years away"}
{"text": "MMCR", "likes": "23", "reply": "@tedyerxa"}
{"text": "EfficientSAM !\nYou liked SAM (Segment Anything Model)?\nYou're gonna love EfficientSAM!\nA smaller, faster, and almost as good version of SAM.", "likes": "749", "reply": " New paper!"}
{"text": "SeamlessExpression: Speech-to-speech translation that preserves the voice and expression of the speaker.", "likes": "304", "reply": "SeamlessExpressive, a new AI translation model by research teams at Meta, enables high-quality speech translation that maintains the speaker's vocal style, tone and unique expressions in translated outputs.\n\nTry the demo with your own voice "}
{"text": "The Cake first appeared in my talk at the NYU future of AI Symposium in early 2016.\nHere is a video from my 2016 NIPS keynote.\nThe point was that there is much more knowledge to extract about the world using self-supervised learning from high-bandwidth sensory input such as…", "likes": "270", "reply": "This also happened in 2016. Whole world was behind end to end RL as the solution to general intelligence after AlphaGo. And "}
{"text": "By \"not any time soon\", I mean \"clearly not in the next 5 years\", contrary to a number of folks in the AI industry.\nYes, I'm skeptical of quantum computing, particularly when it comes to its application to AI.", "likes": "1.4K", "reply": ""}
{"text": "What this NYT article tells us about the genesis of the new AI industry is that there was a lot of drama at Google, DeepMind, OpenAI, and Anthropic.\n\nComparatively, the creation of FAIR was straightforward and drama free.", "likes": "88", "reply": ""}
{"text": "I'm on the cover of the weekly Le Point, as some sort of tiny éminence grise pulling the strings behind \n@elonmusk\n, \n@sundarpichai\n, \n@kaifulee\n and a larger-than-life Sam Altman.\n\nThe title reads \"AI, the battle to control our brains\"\n\nI just want to say that I have no intention of…", "likes": "1.3K", "reply": ""}
{"text": "Haha!\nIt wasn't quite like that.\nMany senior members of the CV community were actually very friendly and curious about ConvNets (if skeptical).\nThere was a true intellectual debate.\nEveryone had to have a \"theory\" of how vision worked.\nFor me, it was end-to-end gradient-based…", "likes": "1.3K", "reply": "Old photo of "}
{"text": "The number of industry labs that practice open research and encourage scientists to publish can be counted on the finger of one hand (if that).\nFAIR is famous for that.\nThis allows scientists to transition to a position in academia if they so decide at some point in their career.…", "likes": "398", "reply": "@rsalakhu"}
{"text": "Débat public sur l'IA, mardi 5 décembre à l'ENS.", "likes": "120", "reply": "Notre prochain mardi réunira Jamal Atif, "}
{"text": "Ross Girschick (\n@inkynumbers\n) is leaving FAIR for AI2, following \n@sainingxie\n who joined the NYU faculty (yay!), and \n@georgiagkioxari\n who went to Caltech, and Hervé Jégou and \n@AlexDefosse\n who went to non-profit Kyutai.\n\nIt's a loss for FAIR, but I'm happy for them.\nThere is…", "likes": "", "reply": ""}
{"text": "SeamlessExpressive: speech-to-speech translation that preserves the voice, the tone, and the expression.", "likes": "465", "reply": "Yesterday we introduced SeamlessExpressive — a new model that preserves unique vocal styles & expression for speech translation, built on our SeamlessM4T v2 foundation model.\n\nMore details on the family of Seamless Communication models "}
{"text": "New open source projects, datasets, and demos released for FAIR's 10th anniversary.", "likes": "328", "reply": "@AIatMeta"}
{"text": "Seamless: speech to text, text to speech, text to text, and speech to speech, transcription and translation in 100 languages.\nFrom FAIR.", "likes": "2.1K", "reply": "Today we're sharing the next milestone in our Seamless Communication research — a new family of AI translation models that preserve expression and deliver near-real time streaming translations.\n\nMore on this new work "}
{"text": "Ego-Exo4D: huge dataset of videos showing human experts doing stuff.\nFrom FAIR.", "likes": "429", "reply": "Today, we announce Ego-Exo4D, the largest and most diverse multi-view dataset, showing human experts around the world performing a core set of skilled activities, w/ unprecedented multi-modality, novel new video-language resources, and rich annotations"}
{"text": "Basically, I'm a \"foundation model\" for celebrities.\nI can be fine-tuned into Harry Potter, Johnny Depp, Snoop Dogg, Taylor Swift, or a slightly overweight version of Mark Zuckerberg.", "likes": "1.1K", "reply": "Due to popular demand, I've fused "}
{"text": "FAIR is turning 10 \nThe creation of FAIR was announced by Mark Zuckerberg, Mike Schroepfer and me at the NeurIPS conference in early December 2013.", "likes": "411", "reply": "10 years of FAIR.\n10 years of advancing the state of the art in AI through open research.\n\nWe're celebrating the 10th anniversary of Meta's Fundamental AI Research team and continuing that legacy by sharing our work on three exciting new research projects today.\n\nDetails below "}
{"text": "FAIR is soon turning 10 years old.\n10 years of published AI research.\n10 years of open source AI software.\nOver 900 GitHub repos.\nhttps://github.com/facebookresearch…", "likes": "420", "reply": "As we approach the 10th anniversary of FAIR, "}
{"text": "Cute.\nVery simple.", "likes": "161", "reply": "Optical illusions with diffusion models. There are so many good gifs on this page but honestly I would like several million more. "}
{"text": "Okay, this has got to be the absolute best use of text-to-image technology ever ", "likes": "1.2K", "reply": "Very excited to share LEDITS++ bringing textual image editing to a new level.\n\nLEDITS++ is\n- fast "}
{"text": "More drama from Sama and Ilya?", "likes": "3.3K", "reply": ""}
{"text": "Leveraging open source LLMs Mistral-7B and Llama2-70B.", "likes": "580", "reply": "We’re thrilled to announce two online LLMs we’ve trained: pplx-7b-online and pplx-70b-online! Built on top of open-source LLMs and fine-tuned to use knowledge from the internet. They are now available via Labs and in a first-of-its-kind live-LLM API. "}
{"text": "AI systems are white boxes that we design \nAs such, they are way easier to align than humans and animals which are black-boxes with all kinds of hard-wired objectives that are immutable and may or may not be \"aligned\", whatever you mean by that.", "likes": "445", "reply": "Introducing AI Optimism: a philosophy of hope, freedom, and fairness for all.\n\nWe strive for a future where everyone is empowered by AIs under their own control.\n\nIn our first post, we argue AI is easy to control, and will get more controllable over time."}
{"text": "A talk about SSL for PDE solving and identification by \n@garridoq_\n as a preview of our upcoming NeurIPS paper.", "likes": "49", "reply": "#AI4Science"}
{"text": "VICReg-style SSL for PDE identification and solving.\nAt NeurIPS 2023.", "likes": "32", "reply": "We will be presenting our work about Self-Supervised learning on PDEs at NeurIPS in two weeks, but if you can't wait or want more details, come check out our talk tomorrow ! twitter.com/AI4scienceTalk…"}
{"text": "Debunking LLM doomerism.", "likes": "199", "reply": "@balesni"}
{"text": "\"Grade A Prime-Cut Bullshit\"", "likes": "67", "reply": "This is some Grade A Prime-Cut Bullshit Tucker Carlson says it is 100% certain that US government has alien spaceships. Why cover it up? ETI tech is so advanced it would end war & the Pentagon makes too much money on the Military Industrial Complex. And it would solve all our… twitter.com/TuckerCarlson/…"}
{"text": "The AI doomers are the \"useful idiots\" of the proprietary AI industry.", "likes": "937", "reply": "@tegmark"}
{"text": "The UAE Minister of AI \n@OmarSAlolama\n points to a historical precedent of premature technology regulation motivated by fear: the ban of the printing press in 1515 by Sultan Selim I led to the decline of the Ottoman Empire.\n\n“We overregulated a technology, which was the printing…", "likes": "", "reply": ""}
{"text": "Funny.", "likes": "186", "reply": "We are entering a new era where mobile chip performance is measured not by GHz, but by Llama2's token/sec "}
{"text": "Good essay on the fallacy of assuming that LLMs are intelligent because they are fluent.", "likes": "504", "reply": "In this new Vox piece written with "}
{"text": "A version of Llama-2 fine-tuned for medicine from EPFL.", "likes": "517", "reply": "Check out our Meditron-7B & 70B "}
{"text": "Haha", "likes": "291", "reply": "AI alarmists, stop HALlucinating."}
{"text": "What children can do that LLMs can't.", "likes": "517", "reply": "@yudapearl"}
{"text": "MMCR: a new learning criterion for Self-Supervised training of joint embedding architectures based on concepts and results from statistical physics.\n\nBy a team from Stanford, NYU, FAIR, and MIT.", "likes": "548", "reply": "Excited to begin announcing our "}
{"text": "Equivariance to translations implies the use of convolutions *if* we insist on using linear operators.\nThere are lots of non-linear operators that are equivariant.", "likes": "165", "reply": "This is the 2nd post in our series on equivariant neural nets. It explains conventional CNNs from a representation theoretic viewpoint and clarifies the mutual relationship between equivariance and spatial weight sharing."}
{"text": "We've barely scratched the surface of the space of deep learning architectures.\n\nIt's a high dimensional space, so the volume is almost entirely contained in the surface.\nBut we've scratched a tiny subset of the surface.", "likes": "2.1K", "reply": "\"Simplifying Transformer Blocks\" ranks easily among my favorite research papers that I've read this year.\n\nHere, the authors look into how the standard transformer block, essential to LLMs, can be simplified without compromising convergence properties and downstream task…"}
{"text": "At least a few of these predictions will come true.", "likes": "326", "reply": "Six predictions for AI in 2024:\n- A hyped AI company will go bankrupt or get acquired for a ridiculously low price\n- Open-source LLMs will reach the level of the best closed-source LLMs\n- Big breakthroughs in AI for video, time-series, biology and chemistry\n- We will talk much…"}
{"text": "Rescheduled.", "likes": "154", "reply": "POSTPONED - AI in Healthcare: The Explainability Dilemma - NEW DATE\n\nOur guests are the leading experts in their respective fields, and we understand that these things can happen!\n\nDue to a last minute change in the agenda of one of our speakers, the live discussion - AI in…"}
{"text": "Popping this up: a response to a question about what I consider reasoning & planning, why current Auto-Regressive LLMs can't do it, why that would require AI systems with world models, and why we still have a lot of progress to do towards AI systems that can learn and reason.", "likes": "721", "reply": "@TEDchris"}
{"text": "Former French minister \n@cedric_o\n responds to \n@tegmark\n's ignominious accusations of corruption surrounding the EU AI Act, and the opposition from the French, German, and Italian governments to regulating foundation model technology.\nCédric says, like me, that he has no issue with…", "likes": "406", "reply": "@tegmark"}
{"text": "But seriously folks, this a short and juicy tirade in which I say:\n(0) there will be superhuman AI in the future\n(1) they will be under our control\n(2) they will not dominate us nor kill us\n(3)  they will mediate all of our interactions with the digital world\n(4) hence, they will…", "likes": "6.3K", "reply": "Can we just make "}
{"text": "Haha ", "likes": "740", "reply": "Can we just make "}
{"text": "Reposting this answer to a question from \n@geoffreyhinton\n about whether I think LLMs \"understand\" what they say.\nI point out what I think is missing from current architectures to reach cat-level intelligence (never mind human level): world models and planning/reasoning abilities.", "likes": "649", "reply": "@geoffreyhinton"}
{"text": "Not a bad set of tenets.", "likes": "112", "reply": "Okay I’ve had enough extremism: I’m founding an AI Centrist Party. Tenets:\n\n* exponentially improving AI isn’t right around the corner\n* LLMs are a massive step in AI capability for any good definition of that word \n* worrying about AI risk is reasonable\n* retweeting Yud is not"}
{"text": "How Effective Altruism fell down a kind of purity spiral.", "likes": "370", "reply": "Effective altruist now seems synonymous with AI doomer, but it wasn’t always that way. My own experience & why I think a lot of it is bullshit AI doomerism now:\n\nI was an active member - went to multiple of their global summits and still mostly donate to causes that they… twitter.com/sapinker/statu…"}
{"text": "Yuandong is one of several folks who have been working on planning at FAIR.\nHe explains the difference in applicability between A* (search for shortest path in a graph) and MCTS (search in an exponentially growing tree).", "likes": "668", "reply": "How likely is the hypothesis that Q* = Q-learning + A*?\n\nFrom my past experience on OpenGo (reproduction of AlphaZero), A* can be regarded as a deterministic version of MCTS with value (i.e., heuristic) function Q only. This should be suitable for tasks in which the state is easy…"}
{"text": "Exactly.\nYuandong has been working on various approaches to planning at FAIR.", "likes": "147", "reply": "I partly disagree that AGI can be just solved by scaling up with synthetic data.  \n\nThe reason why search is powerful, is that for properly designed environment, it will create infinitely new patterns for the model to learn & adapt. However, whether learning such new patterns… twitter.com/DrJimFan/statu…"}
{"text": "Built with MusicGen and Demucs, both open source packages from Meta-FAIR.\nhttps://huggingface.co/spaces/facebook/MusicGen…\nhttps://github.com/facebookresearch/demucs…", "likes": "329", "reply": "Introducing Remix - a tool made with Nendo that generates remixes of any song in any style. Upload a song or YT video & have fun! (For research purposes only. Usage is at your own risk)  \n\nColab: "}
{"text": "Video of my public interview with Brian Greene at the World Science Festival in NYC a few weeks back.\nIt is followed by a debate about \"AGI\" with \n@SebastienBubeck\nIt ends with a debate about AI safety with Sébastien and Tristan Harris.\nI find it strange that Tristan uses the…", "likes": "", "reply": ""}
{"text": "The cideo of our AGI debate premieres 75 minutes from now.", "likes": "242", "reply": "Join us on YouTube at 1pm PT/4pm ET today for the premiere of our \"debate\" with "}
{"text": "Please ignore the deluge of complete nonsense about Q*.\nOne of the main challenges to improve LLM reliability is to replace Auto-Regressive token prediction with planning.\n\nPretty much every top lab (FAIR, DeepMind, OpenAI etc) is working on that and some have already published…", "likes": "", "reply": ""}
{"text": "Or even just a working cat bot.", "likes": "813", "reply": "We need a moratorium on talking about looming AGI until we have at least a working housebot."}
{"text": "The dystopian fantasy of machines taking over humanity is so old that it's a cliché.", "likes": "1.1K", "reply": "'Lowly Machines to Overtake Man, Rule Universe' (1948) "}
{"text": "Current LLMs are trained on text data that would take 20,000 years for a human to read.\nAnd still, they haven't learned that if A is the same as B, then B is the same as A.\nHumans get a lot smarter than that with comparatively little training data.\nEven corvids, parrots, dogs,…", "likes": "8K", "reply": "@DrJimFan"}
{"text": "GAIA: A benchmark for general AI assistants,\nby a team from Meta-FAIR, Meta-GenAI, HuggingFace, and AutoGPT.\n\nCurrent Auto-Regressive LLMs don't do very well.", "likes": "1.2K", "reply": "GAIA: a benchmark for General AI Assistants\n\npaper page: "}
{"text": "Interesting list.", "likes": "144", "reply": "The top 15 most-liked organizations on "}
{"text": "Periodic reminder.", "likes": "274", "reply": "@HistedLab"}
{"text": "One of the most important reason why AI infrastructure models must be open source, and their training/fine-tuning must be crowd-sourced.", "likes": "1.3K", "reply": "An interesting aspect of this discussion is the fact that LLMs will soon start affecting our thoughts, beliefs, mental & linguistic habits, and culture. The idea that we could select a handful of \"trustworthy\" institutions with the \"correct\" set of values and beliefs to shape LLM… twitter.com/karpathy/statu…"}
{"text": "System 2 Attention.\nMaking LLM reason.\nFrom \n@jaseweston\n and \n@tesatory\n at FAIR.", "likes": "1K", "reply": " New paper! "}
{"text": "One might run into this poster at various airports around the world.", "likes": "782", "reply": "Pionnier de l’intelligence artificielle. Lauréat du prix Turing. "}
{"text": "To everyone who lives in a civilized country and thinks their health insurance system sucks: \nBe thankful you don't live in the United States.", "likes": "1.8K", "reply": "A thread about our depraved healthcare system, and a plea.\n\nIn 2021, my friend Carole was diagnosed with terminal stage four cancer. A single parent with two kids, she had just turned 43. In 2017, she had watched her brother Chris die of the same cancer. He too was in his 40s."}
{"text": "Research strives on stability.\nWhen your horizon is 3, 5, or 10 years, you need stability.\nThere are very, very few stable and  sustainable models for research.\nI'm talking about research, not product development.", "likes": "", "reply": ""}
{"text": "s/strives/thrives/", "likes": "", "reply": ""}
{"text": "There is at least one industry research lab where the leadership believes that (super)human-level AI:\n- is attainable\n- is a scientific research question, not just a question of more compute and more data.\n- is not \"just around the corner\". It will take a while.\n- is not an…", "likes": "", "reply": ""}
{"text": "Another open source LLM from France.\nThey keep piling up.", "likes": "782", "reply": " Big news from "}
{"text": "Still lots of conceptual progress to be made in AI.\nThis is a scientific question.\nNot merely a question of more compute and more data.", "likes": "1.1K", "reply": "“Machine learning sucks!” Keynote by "}
{"text": "Governments should be careful to listen to people who know what they are talking about, and be skeptical of people who don't.", "likes": "646", "reply": "Politico reports Tristan Harris helped inspire Biden’s executive order on AI. ("}
{"text": "Science is not a zero-sum game.\nWith more scientists, research accelerates.\nBut no one has a monopoly on good ideas.\nSo, with and more and faster communication, research accelerates further.", "likes": "519", "reply": "Science is not a zero-sum game. With more knowledge, we can do more things, with less.\n\nScience is not a zero-sum game. With more funding, more labs, we’ll train more students, and grow the pie for all.\n\nScience is not a zero-sum game. Publish, I can build on your breakthrough."}
{"text": "Pretty much the most important question in the debate about short-term risks of LLMs.\nNo clear evidence so far.", "likes": "341", "reply": "Is there any known case of anyone accessing “harmful capabilities” of an LLM that didn’t consist of knowledge already freely available and clearly described in documents on the open web?\n\nIs the fear that we are basically just getting what we would already have if Google / Bing…"}
{"text": "OpenAI’s Board Pushes Out Sam Altman, Its High-Profile C.E.O.", "likes": "221", "reply": ""}
{"text": "Kyutai: a new non-profit AI research lab based in Paris dedicated to open science.\nThe founding members are top notch.", "likes": "763", "reply": "Announcing Kyutai: a non-profit AI lab dedicated to open science. Thanks to Xavier Niel ("}
{"text": "Translation: Auto-Regressive LLMs scaling is giving diminishing returns.\n\nAs I've said repeatedly, a new architecture will emerge for the next leap, perhaps along the lines of the Objective-Driven AI I've been proposing.\n\nBut deep learning will still be the foundation. No wall.", "likes": "1.2K", "reply": "Translation: “deep learning is hitting a wall” twitter.com/burny_tech/sta…"}
{"text": "Cool image editing with Emu-Edit from Meta.", "likes": "255", "reply": "Look at the fine image editing control.\nEmuEdit is pretty cool!"}
{"text": "Weird doomer argument: \"society should not deploy <technology-X> because *I* don't fully understand it, and I believe no one else does, either.\"", "likes": "", "reply": ""}
{"text": "Genau,", "likes": "33", "reply": "@BertuzLuca"}
{"text": "Emu video & Emu edit: video generation and image animation.", "likes": "290", "reply": "Today we’re sharing two new advances in our generative AI research: Emu Video & Emu Edit.\n\nDetails "}
{"text": "Mistral's official stance on the EU AI Act.\nTL;DR: regulate products, don't regulate technology.\nPromote open source foundational models.\nAt the very least, don't regulate them in ways that favor incumbents.", "likes": "489", "reply": "We have heard many extrapolations of Mistral AI’s position on the AI Act, so I’ll clarify.\n\nIn its early form, the AI Act was a text about product safety. Product safety laws are beneficial to consumers. Poorly designed use of automated decision-making systems can cause…"}
{"text": "That's pretty insane!", "likes": "1.2K", "reply": "Hack of the day: Llama on a microcontroller"}
{"text": "Truth hurts.\nBut not as much as bullets.", "likes": "762", "reply": "The House GOP just voted to prevent the CDC from studying gun deaths and injuries. Hmm...I wonder why?"}
{"text": "There isn't a shred of evidence that AI poses a paradigmatic shift in safety.\n\nIt's all fantasies fueled by popular science fiction culture suggesting some sort of imaginary but terrible, terrible catastrophic risk.", "likes": "893", "reply": "There isn't a shred of evidence that AI poses a paradigmatic shift in safety that requires new regulation.   \n\nAnd we should not draft charters or policies that suggest differently."}
{"text": "Llama as a service on Azure.\nMistral as a service on Azure.\nThrilled to see that Microsoft and \n@satyanadella\n are supporting open source AI platforms for their customers.", "likes": "815", "reply": "Copilot will be the new UI for both the world's knowledge and your organization's knowledge, but most importantly, it will be your agent that helps you act on that knowledge. Here are highlights from my keynote today at "}
{"text": "Lots more open source AI goodies here.\nIncluding FAISS, DINOv2, Detectron2, Segment Anything, CodeLlama, Nougat, PyTorch-BigGraph, fastText, ...\nhttps://github.com/facebookresearch…", "likes": "796", "reply": "Zuck has so far open sourced and given the world:\n◆ React\n◆ React Native\n◆ PyTorch\n◆ Llama\n◆ GraphQL\n◆ Flow\n◆ Jest\n◆ Relay\n◆ HHVM / Hack\n◆ Yoga\n◆ Hermes\n◆ RocksDB\n◆ Zstandard\n\nGoated."}
{"text": "\"Is France the Next Open-Source AI Capital?\"\n\nMais oui !", "likes": "912", "reply": "Let's do it "}
{"text": "Want to use AI for good?\nHow about using AI to help discover new chemical compounds that would solve the energy storage problem?\nIf energy storage were solved, we could cover a small desert with solar panels and power the world.", "likes": "531", "reply": "Announcing the Open Catalyst Intro video series! Want to learn more about how we can help mitigate climate change through advances in AI and chemistry? We’re creating a video series to help AI researchers get up to speed in this exciting research area!"}
{"text": "American exceptionalism:\nDying from preventable causes and spending a lot for it.", "likes": "229", "reply": "This chart shows a comparison of health systems performances and resources.\n\nThe most effective are the closest to the origin, with lower mortality rate from avoidable causes and lower expenditure per capita.\n\n["}
{"text": "The US economy is doing amazingly well.\nBut half the population has been brainwashed into thinking that things are bad.", "likes": "1.6K", "reply": "Labor productivity up 4.7% last quarter. \n\nReal wages at record highs. \n\nUnemployment near record lows. \n\nNow headline inflation coming in at 0% this month. \n\nThe US economy is absolutely CRUSHING it. twitter.com/jasonfurman/st…"}
{"text": "The whole story of Galactica, told by its first author \n@rosstaylor90\n.\n\nYou know the open source mantra \"release early, release often\"?\nWhen it comes to AI, one should add \"yes, but be prepared to ignore ridiculous prophecies of doom from Twitter mobs.\"", "likes": "297", "reply": "I am the first author of the Galactica paper and have been quiet about it for a year. Maybe I will write a blog post talking about what actually happened, but if you want the TLDR:\n\n1. Galactica was a base model trained on scientific literature and modalities. \n2. We approached… twitter.com/sharongoldman/…"}
{"text": "This is *not* \"Big Tech\" versus The People or whatever.\nThis is open source AI versus closed and proprietary AI.\n\nOn the one hand, you have Mistral, Aleph, HuggingFace, Meta, IBM, and the entire startup ecosystem arguing for open source AI foundation models.\nOn the other hand,…", "likes": "1.5K", "reply": "This last-second attempt by big tech to exempt the future of AI (LLMs) would make the EU AI Act the laughing-stock of the world, not worth the paper it’s printed on. After years of hard work, the EU has the opportunity to lead a world waking up to the need to regulate these… twitter.com/BertuzLuca/sta…"}
{"text": "Galactica, the LLM for scientists from Meta, was released a couple of weeks before ChatGPT but was taken down after 3 days.\nIt was murdered by a ravenous Twitter mob.\nThe mob claimed that what we now call LLM hallucinations was going to destroy the scientific publication system.…", "likes": "2.9K", "reply": "One year ago — 2 weeks before "}
{"text": "A piece by MBZUAI president \n@ericxing\n in WEF Agenda explaining why worries about AI existential risks are baseless.", "likes": "84", "reply": "The dystopian AI predictions owe more to sensationalism than scientific substance. Read my latest article on World Economic Forum's Agenda where I explain why AIXrisk is baseless, and AI is a catalyst for human advancement rather than a harbinger of doom."}
{"text": "For cultural_phenomenon in [novels, waltz, cinema, jazz, radio, TV, comics, video games, D&D, internet, social networks, chatbots] :\n  Print( cultural_phenomenon, \" is a waste of time that destroys the mind of the youth.\")", "likes": "229", "reply": "1849 article on the vice of novel reading:\n\n- \"The natural affections of the soul become perverted.\"\n\n- \"Vice is often represented as virtue; wisdom and discretion as folly.\"\n\n- \"Time is wasted, the taste is vitiated and corrupted; the improvement of the mind is prevented\""}
{"text": "Giving a talk at the AI New Horizon Symposium in Hong Kong Saturday Nov 18.\n\nOrganized by \n@pascalefung\n, \n@harryshum\n, and Nancy Ip from HKUST.\n\nhttps://ai-newhorizons2023.com", "likes": "106", "reply": ""}
{"text": "Exactly.", "likes": "268", "reply": "The most effective risk mitigators are determinate optimists. \n\nThey believe in solutions. \n\nThey’re often drowned out by the least effective risk mitigators: the indeterminate pessimists. \n\nWhy? Because they’re too busy building solutions to write op-eds and do Ted talks."}
{"text": "The scientists and engineers who have made turbojets as safe and reliable as they are today have been determinated optimists.", "likes": "", "reply": ""}
{"text": "s/determinated/determined/", "likes": "", "reply": ""}
{"text": "Beware of testing on the training set.", "likes": "1.4K", "reply": "The famous \"Chihuahua or Muffin\" problem in computer vision is considered solved by GPT-4V on social media. But really? The answer is NO. GPT-4V cannot reason well about the same images in the original \"Chihuahua or Muffin\" grid when they are in a different layout. \n\nI…"}
{"text": "LLMs as role-playing engines.", "likes": "326", "reply": "My new "}
{"text": "An X/Twitter fake account named \"yylecun\" is impersonating me.\nIt DMs people to peddle cryptocrap.\nI flagged it but it's still around.", "likes": "", "reply": ""}
{"text": "Nick Bostrom attempting to stamp down the AI doomer movement he jumpstarted from falling into a purity spiral and extremist oblivion.\nAI doomerism is doomed.", "likes": "721", "reply": "Here is Nick Bostrom admitting that AI panic feels out of control right now, \"like a wrecking ball\" that could \"destroy the future\" "}
{"text": "The original AI doomers are leaving the sinking ship of AI doomerism.", "likes": "692", "reply": "On Bostrom\nYudkowsky must feel lonely now. "}
{"text": "It was great to meet science fiction writer Qiufan \"Stanley\" Chen before our panel on AI at the Paris Peace Forum.", "likes": "308", "reply": ""}
{"text": "A panel on AI at the Paris Peace Forum today.\n\nStarting at 42'00, I plot the future of AI: all of our interactions with the digital world will be mediated by AI assistants that will eventually become smarter than us.\nBecause they will become a common infrastructure containing all…", "likes": "", "reply": ""}
{"text": "Very strange anti-openness argument from Microsoft President Brad Smith in response to my open source AI platform advocacy.\n\nI thought Microsoft had long abandoned its anti open source stance.\nDoesn't Azure run on Linux?", "likes": "1.1K", "reply": "\"It all depends on your definition of open\" -- Brad Smith, Microsoft"}
{"text": "A curious response from Microsoft President Brad Smith, in response to my advocacy for open source AI platforms at the Paris Peace Forum today.\n\nHe claimed Llama isn't open because Meta is controlled by one person while OpenAI is trustworthy because it is owned by a non-profit.", "likes": "764", "reply": "Outrageous!!\n\nMassive misrepresentation by Brad Smith (MSFT) claiming chat-gpt is as open as LLaMa (among other non truths)\n\nIt's sad to see MSFT become the enemy to open source again. They did it during the OS / browser wars. And they're doing it again."}
{"text": "Interesting development.", "likes": "168", "reply": "There is nothing better than some Friday drama to close such a hectic week. A technical meeting on the "}
{"text": "The full story of the open-access Deep Learning course that Alfredo Canziani and I have been teaching together and refining over the last several years.", "likes": "1.1K", "reply": ""}
{"text": "The fears of AI-fueled existential risks are based on flawed ideas.\nA WSJ piece by Princeton's \n@random_walker\n and \n@sayashk\n .", "likes": "54", "reply": "@sayashk"}
{"text": "An article about the bubbling AI startup ecosystem in Paris and the important role FAIR-Paris played in seeding it.", "likes": "313", "reply": ""}
{"text": "Big AI industry event at Station F in Paris, Friday Nov 17.\n\nKeynote Speakers: Eric Schmidt (Schmidt Future), Jensen Huang (CEO Nvidia), Xavier Niel (Iliad/Scaleway).\n\nSpeakers include: Thomas Scialom (Meta, of Llama fame), Arthur Mensch (CEO Mistral, or Mistral-7B fame), Jason…", "likes": "", "reply": ""}
{"text": "NYU is clearly where AI professors want to be.\nOpen faculty positions in AI at NYU.", "likes": "223", "reply": "We have open-rank faculty positions in AI at "}
{"text": "Knowledge is not understanding.\nReminds me of the folks who have tried wearing prism glasses that invert the world.\nThey get used to it after a few weeks of practice.\nThen they get all confused when they remove the glasses.\nBut it only takes a short time to recover.", "likes": "328", "reply": "@ylecun"}
{"text": "Open source AI is the way to go!\n\nProud to see  \n@huggingface\n, \n@scaleway\n, & \n@meta\n joining to launch an AI startup accelerator at Station F.\nThis will help concretize our common vision of an open and collaborative AI ecosystem.\n\nMore from TechCrunch:", "likes": "1.4K", "reply": ""}
{"text": "L’IA open source est la voie à suivre ! \n\nJe suis fier de voir \n@huggingface\n, \n@scaleway\n et \n@meta\n unir leurs expertises pour lancer un programme d’accélération de startups à Station F  et ainsi matérialiser la vision d’un écosystème de l'IA ouvert et collaboratif !…", "likes": "", "reply": ""}
{"text": "LLMs don't even know how to climb stairs.", "likes": "791", "reply": "@boazbaraktcs"}
{"text": "The phrase \"whole career\" is particularly accurate.\n\n1. Pick a difficult technology area. Anything: Flying cars, quantum computing, interstellar travel, nuclear fusion, hypersonic flight, AI, whatever.\n2. Complain that \"current approaches are hitting a wall and will never work.\"…", "likes": "1.9K", "reply": "It's amazing that one can make a whole career of only spouting pessimistic interpretations a field that is clearly advancing to amazing capabilities. "}
{"text": "My wife has an MNIST-like tailleur.\n(here with \n@pascalefung\n and \n@frossi_t\n ).", "likes": "208", "reply": ""}
{"text": "High-performance open-source LLMs popping up around the world.\nDoes anyone believe regulating AI R&D can be effective?\n(Assuming it's useful. Which it is not).", "likes": "727", "reply": "http://01.AI"}
{"text": "Well, technically, my first paper on Joint Embedding Architectures (AKA Siamese nets) is from NIPS 1994.\nbut that paper and many subsequent works use sample-contrastive learning and no predictor.\nThe JEPA idea trained non sample-contrastive losses (Barlow Twins, VICReg, MCR2) or…", "likes": "195", "reply": "In 2022 Yann LeCun submitted a paper on joint embedding predictive architectures for learning representations.\n\nHow many years will it take for people to finally warm up to his ideas? "}
{"text": "Don't confuse the approximate retrieval abilities of LLMs for actual reasoning abilities.", "likes": "717", "reply": "LLM's seem to fake both \"solving\" and \"self-critiquing\" solutions to reasoning problems by approximate retrieval. The two faking abilities just depend on different parts of the training data (..and disappear when such data is not present in the training corpus..)\n\nOur recent… twitter.com/rao2z/status/1…"}
{"text": "In 1983, when the free world was starting to play with personal computers, the Ceaucescu regime in Romania required a license to own a typewriter.\nObscurantism isn't just preventing people from accessing knowledge.\nIt's also preventing people from exchanging knowledge.", "likes": "922", "reply": "https://newsletter.pessimistsarchive.org/p/remember-typewriter-licenses…"}
{"text": "So much for the idea that self-driving cars are hitting walls.\nThey are not hitting obstacles nearly as much as human drivers.\n\nYes, Waymo cars only drive in some areas that are fully mapped, they use all kinds of sensors, and they have required a decade of data collection,…", "likes": "1K", "reply": "Waymo self-driving cars already appear to be much safer than human drivers: 1/4 the accident rate of the average person insured by SwissRe. \n\nAnd as "}
{"text": "Any takers? https://t.co/4TobcpwIRR", "likes": "493", "reply": ""}
{"text": "An interview with \n@craigss\n on Eye on AI where I talk about world models, JEPA, the future of AI, and the necessity of open source AI platforms.", "likes": "97", "reply": "This is one of the most enlightening conversations I've had. Please listen. I think Yann is far ahead of the rest of the AI research community and I think world models will soon surpass LLMs in exhibiting true intelligence. "}
{"text": "An interview in Computer Vision News: Self-Supervised Learning,  JEPA, and the future of AI.", "likes": "222", "reply": "Hot off the press - Computer Vision News is out!"}
{"text": "Hahahaha *pant pant* hahahaha", "likes": "216", "reply": "Collective amnesia about technophobia is ENDEMIC.\n\n‘It is different this time’ is NOT an excuse to ignore history.\n\nEncryption panic threatend privacy.\n\nGMO panic killed millions through malnutrition.\n\nNuclear panic delayed critical carbon free future. "}
{"text": "AI regulatory capture recipe.", "likes": "374", "reply": "Regulatory capture in a nutshell: \n\n1) Get the uninformed general public terrified of vague threats\n3) Frame it as \"for the greater good\"\n4) Employ true believers/well intention extremists\n5) Co-opt ^^ useful idiots\n6) Gov eliminates competition for you!"}
{"text": "Excellent thread by Stanford's \n@percyliang\n with a list of reasons why open source AI platforms are inherently *safer* than closed source ones.", "likes": "395", "reply": "Myth: open foundation models are antithetical to AI safety.\nFact: open foundation models are critical for AI safety.\nHere are three reasons why:"}
{"text": "YES!\nOne can believe that LLMs can do amazing things and are useful, *without* believing they are anywhere close to human-level intelligence (even if they are superior to humans in a few tasks).\n\nOne can believe that LLMs will give new tools to people with bad intention *without*…", "likes": "793", "reply": "You can be amazed at Generative AI (and LLMs), while still recognizing their limitations.\n\nYou can be concerned about Generative AI (and LLMs) opening up new attack surfaces, while still not stressing about fake threats.\n\nYou can resist both hype and doom. \n\nImagine!"}
{"text": "VentureBeat writes about the earth-shattering effect of the release of Llama and Llama-2 on the LLM landscape.", "likes": "318", "reply": ""}
{"text": "Obscurantism recedes with education.", "likes": "203", "reply": "Incredible progress over several centuries in providing some measure of formal education "}
{"text": "Some people are assimilating the risks associated with pandemics with the risks associated with AI progress.\nThere is a fundamental difference.\n\nPandemics are natural phenomena.\nWe can take preventive measures before they happen and plan for corrective measures in case they do.…", "likes": "", "reply": ""}
{"text": "The idea that knowledge is too dangerous for people to have access to it has a name:\nObscurantism.", "likes": "", "reply": ""}
{"text": "That's because finding cures for cancer with the help of AI will involve thousands of the best biomedical and computer scientists in the world, with lots of funding, lots of computing resources, lots of open information exchange, and lots of clinical trials.\n\nOn the contrary,…", "likes": "1.2K", "reply": "@BlancheMinerva"}
{"text": "I signed this open letter to President Biden to argue that Executive Orders and regulations of AI should promote open source AI platforms, and certainly not hinder them.\n\nSigned by execs from Meta, HF, Mistral, Shopify... as well as a number of prominent execs from the VC world.", "likes": "1.8K", "reply": "1/ We’ve submitted a letter to President Biden regarding the AI Executive Order and its potential for restricting open source AI. We believe strongly that open source is the only way to keep software safe and free from monopoly. Please help amplify."}
{"text": "I'm glad \n@arthurmensch\n and \n@nickclegg\n were present for the second day of the AI Safety Summit to defend the idea of open-source AI research, code, and models.\n\n(I was there the 1st day but wasn't invited to the 2nd day)", "likes": "190", "reply": "Leaving the AI Safety Summit after some constructive discussions today and yesterday. I voiced how open-source was today the safest way to develop AI, putting this transformative technology under the highest level of scrutiny. \n\nWith many others, we recalled the enormous…"}
{"text": "Very interesting thread from a computer security expert.\nHe says:\n1. Building something that works in the real world is harder than what most armchair AI safety folks think.\n2. there is a natural tendency to exaggerate the potential risks of your own work, because it makes you…", "likes": "1.7K", "reply": "I wish I had more time to chime into the AI doom debate, but here a very quick thread:\n\n1) The one thing all AI doomers seem to assume is that almost all engineering problems can be solved by thinking, vs. experimentation.\n2) Humanity has seen multiple individuals of ..."}
{"text": "Hahaha ", "likes": "1K", "reply": "Sigh"}
{"text": "The acceleration of scientific progress with the help of AI is super exciting.", "likes": "260", "reply": "What do you think foundation models should do for your science topic?   "}
{"text": "Excellent interview of \n@bgurley\n in which he forcefully defend the idea of open source AI platforms.", "likes": "197", "reply": "I interviewed Bill Gurley "}
{"text": "Good news everyone: The UK Deputy Prime Minister understands the benefits of open source AI platforms.", "likes": "380", "reply": "@vmanancourt"}
{"text": "How long before regulators realize that search engines still produce more accurate information than LLMs?\nThey both use the same public data.\nSearch engines index it.\nLlama summarizes it approximately.", "likes": "1.3K", "reply": "I am mystified by the \"Oh my god, bad hombres can find how to make weapons/viruses by querying LLMs\" angst. These hombres didn't have access to Google until ChatGPT came along? After all, every bit of ChatGPT training data also indexed by Google--no?  \n\nI mean, I haven't been… twitter.com/rao2z/status/1…"}
{"text": "s/Llama/LLM/\nFunny how my spell checker automatically changes \"LLM\" into \"Llama\" behind my back ", "likes": "", "reply": ""}
{"text": "An extensive comparison of various architectures, various (pre-) training procedures, on various vision tasks.\nTL;DR: use ConvNext.", "likes": "236", "reply": "Excited to announce a large-scale comparison of pretrained vision backbones including SSL, vision-language models, and CNNs vs ViTs across diverse downstream tasks ranging from classification to detection to OOD generalization and more! NeurIPS 2023"}
{"text": "If AI can help the bad guys, it can also help the good guys protect against the bad guys.", "likes": "738", "reply": "If AI actually gets good at finding security vulnerabilities, software will quickly become much more secure."}
{"text": "The field of AI safety is in dire need of reliable data .\nThe UK AI Safety Institute is poised to conduct studies that will hopefully bring hard data to a field that is currently rife with wild speculations and methodologically dubious studies.", "likes": "", "reply": ""}
{"text": "Perhaps an LLM can save you a bit of time, over searching for bioweapon building instructions on a search engine.\nBut then, do you know how to do the hard lab work that's required?", "likes": "392", "reply": "@katieelink"}
{"text": "Yes, that's one scenario I was thinking of.", "likes": "136", "reply": "@katieelink"}
{"text": "An excellent piece by my dear NYU colleague \n@togelius\n pointing out that regulating AI R&D (as opposed to products) would lead to unacceptable levels of policing and restrictions on the \"freedom to compute\"", "likes": "296", "reply": "I think regulating AI on a technical level (as opposed to an application level) is a terrible, terrible idea and a threat to our digital freedoms. This is a text I've had half-finished for a while, but recent developments made me finish it up."}
{"text": "An article about my vociferous support of open source AI platforms.\nDemis Hassabis, Dario Amodei, and Sam Altman (among others) have scared governments about what they claim are risks of AI-fueled catastrophes.\n\nI know that Demis, at least, is sincere in his claims, but I think…", "likes": "", "reply": ""}
{"text": "Openness, transparency, and broad access makes software platforms safer and more secure.\nThis open letter from the Mozilla Foundation, which I signed, makes the case for open AI platforms and systems.", "likes": "871", "reply": ""}
{"text": "Open source platforms *increase* safety and security.\nThis is as true for AI as it is for operating systems and Internet infrastructure software.", "likes": "602", "reply": "@arthurmensch"}
{"text": "Important point from \n@arthurmensch\n.\nIn fact, AI is often the best countermeasure to things like disinformation campaigns and cyber attacks.", "likes": "157", "reply": "@arthurmensch"}
{"text": "Exactly.", "likes": "455", "reply": "It may soon be a crime to compress public domain human knowledge into public domain matrices. We need to regulate the usage of AI in applications, not gradient descent"}
{"text": "Good question.", "likes": "192", "reply": "I have a family member studying virology. Everyone in the course is learning this forbidden knowledge that LLMs are not allowed to pass on.\n\nSo why do we allow the teaching of virology, but do not allow an understanding of virology to be more accessible? twitter.com/DrNikkiTeran/s…"}
{"text": "Like when there was an export control on computers above 1 GFLOPS  and when the Sony PlayStation-2 came out in 2000, it was above the limit \nhttps://theregister.com/2000/04/17/playstation_2_exports/…", "likes": "852", "reply": "One day we will have the equivalent of the gpu compute Azure has in an iPhone and this regulation will seem comical to our children."}
{"text": "Exactly.", "likes": "235", "reply": "The gun control lobby can bring statistics to bear and say “Perhaps it is worth giving up some liberty in an attempt to limit these manifest harms.” You can disagree, but it is a reality based argument. In contrast, the AI control lobby holds up imaginary harms."}
{"text": "A nice piece by \n@AndrewYNg\n arguing that irrational fears about AI should not cause governments to regulate open source AI models out of existence.", "likes": "1K", "reply": "My greatest fear for the future of AI is if overhyped risks (such as human extinction) lets tech lobbyists get enacted stifling regulations that suppress open-source and crush innovation. \n\nRead more in our Halloween special issue of the Batch: "}
{"text": "A few interesting points highlighted by \n@kchonyc\n in the President's Executive Order on AI.", "likes": "35", "reply": "a number of weird definitions and weirdly specific points, but overall, worth reading it to see which areas are considered as priorities by WH. in this "}
{"text": "I have a terrible confession to make: \nI giggled ", "likes": "1K", "reply": "The psychology of AI alarmists:\n\nElon Musk: Savior complex. Needs something to save the world from.\n\nGeoff Hinton: Ultra-leftist, world-class eccentric.\n\nYoshua Bengio: Hopelessly naive idealist.\n\nStuart Russell: His only impactful application ever was to nuclear test monitoring.…"}
{"text": "The groundswell of interest for Llama-1  (and for all our previous open source AI packages, Like PyTorch, DINO, SAM, NLLB, wav2vec...) is what convinced the Meta leadership that the benefits of an open release of Llama-2 would overwhelmingly outweigh the risks and transform the…", "likes": "1.5K", "reply": "Realizing how important it was for "}
{"text": "Yup. I've said that for years too.", "likes": "323", "reply": "Yap. As I've said for years:\nRegulate applications of AI, not general/foundational model research. twitter.com/ClementDelangu…"}
{"text": "Well, at least *one* Big Tech company is open sourcing AI models and not lying about AI existential risk ", "likes": "308", "reply": ""}
{"text": "Yes. Regulate end product deployments.\nDon't regulate R&D with an arbitrary compute or mode size threshold.", "likes": "676", "reply": "IMO compute or model size thresholds for AI building would be like counting the lines of code for software building. \n\nRegulation based on this will most likely be easily fooled, create hurdles/worries for companies to compete on bigger models (so concentration of power) and slow…"}
{"text": "s/mode/model/", "likes": "", "reply": ""}
{"text": "I agree with \n@rao2z\n on all of his points.", "likes": "91", "reply": "The debate on AI risks and need for legislation is a complex one and my own position is not exactly identical to anything any of the key players have already publicized.\n\nI will however list some points of concurrence. )Not that anyone asked.. "}
{"text": "Another comment to a tweet from \n@tegmark\n asking me (again) why I think AI won't kill us all, and claiming that the question of existential risk is disconnected from the question of open source AI.", "likes": "194", "reply": "@tegmark"}
{"text": "Excellent #SundayHarangue from Rao:\nAuto-Regressive LLMs are \"powerful cognitive crutches\" but are nowhere near human intelligence.\nThey can do things that humans suck at.\nBut they really suck at planning, reasoning, logic, understanding the physical world, etc.\nAll things that…", "likes": "265", "reply": "Why we should view LLMs as powerful Cognitive Orthotics rather than  alternatives for human intelligence  "}
{"text": "Since many AI doom scenarios sound like science fiction, let me ask this:\nCould the SkyNet take-over in Terminator have happened if SkyNet had been open source?", "likes": "", "reply": ""}
{"text": "A defense of open R&D in AI, posted as a comment to a question by \n@tegmark\n.", "likes": "742", "reply": "@tegmark"}
{"text": "Awesome study led by \n@AlisonGopnik\n on the capabilities of LLMs from the psychologists' standpoint.\n\nQuote: \"Large language models such as ChatGPT are valuable cultural technologies. They can imitate millions of human writers, summarize long texts, translate between languages,…", "likes": "466", "reply": "Our latest paper, in Perspectives on Psychological Science, with Eunice Yiu and Eliza Kosoy, articulating the idea of Large AI Models as cultural technologies at more length and comparing and contrasting  with human children"}
{"text": "Open source AI platforms aren't just cheaper.\nThey are more efficient and more customizable.", "likes": "655", "reply": "New: OpenAI customers are eyeing other options to save AI compute costs. Companies like Salesforce and Wix say they're testing open source to replace OpenAI where feasible. \n\nAzure OpenAI Service is also winning some business away from pure-play OpenAI."}
{"text": "One thing we know is that if future AI systems are built on the same blueprint as current Auto-Regressive LLMs, they may become highly knowledgeable but they will still be dumb.\nThey will still hallucinate, they will still be difficult to control, and they will still merely…", "likes": "1.7K", "reply": "New paper:"}
{"text": "How to get started with Llama-2 ?\nHere is a comprehensive tutorial.", "likes": "1.7K", "reply": ""}
{"text": "Petition \"freedom for kidnapped children\"\nSigned by laureates of the Fields Medal, Abel Prize, Nevanlinna Prize, Breakthrough Prize, ACM Turing Award, and ACM Prize in Computing.", "likes": "3.6K", "reply": ""}
{"text": "Compute is all you need.\nFor a given amount of compute, ViT and ConvNets perform the same.\n\nQuote from this DeepMind article: \"Although the success of ViTs in computer vision is extremely impressive, in our view there is no strong evidence to suggest that pre-trained ViTs…", "likes": "", "reply": ""}
{"text": "Another great piece by \n@Jake_Browning00\n on the limitations of current AI systems.\nThey are boring ", "likes": "342", "reply": "Now that both Altman and Gates are acknowledging scaling up won't help these models improve, I think it is safe to pronounce a verdict on the current approach to generative AI: it's boring.\n  "}
{"text": "On This Day 6 years ago: the first general meeting of the Partnership on AI took place in Berlin.\n\nPAI funds studies and publishes guidelines on questions of AI ethics and safety.\nIt just published a set of guidelines for the safe deployment of foundation models:…", "likes": "147", "reply": ""}
{"text": "The Partnership on AI is publishing guidance for safe foundation model deployment.\n\nThere is a request for comments on the current version", "likes": "121", "reply": ""}
{"text": "I made that point during the Munk Debate in response to Max Tegmark (who is a physics professor at MIT): \"Why aren't you worried that some students in your nuclear physics class could be baby Hitlers?\"", "likes": "153", "reply": "I agree with "}
{"text": "An interview of me in the Financial Times in which I explain the reasons for supporting  open research in AI and open source AI platforms.\nI also explain why the widely-publicized prophecies of doom-by-AI are misguided and, in any case, highly premature.", "likes": "981", "reply": ""}
{"text": "A quick review of my talk in Munich late last month.", "likes": "255", "reply": "Professor Yann LeCun recently gave a talk titled \"From Machine Learning to Autonomous Intelligence\"\n\nThe presentation covers an important topic:\n\nAI systems that can learn, remember, reason, plan, have common sense, yet are steerable and safe.\n\nHere is a short summary:"}
{"text": "Simple truths.", "likes": "390", "reply": "Slowing down AI innovation with regulation is a very bad idea and will only have negative consequences\n\n- Traditionally, regulation helps large monopolies and big companies and cripples start-ups\n\n- US-centric regulation will lead to the US falling behind "}
{"text": "Incidentally:\n- I am not anti-regulation.\n- regulating the deployment of *product* is useful to guarantee safety. \n- but I'm very much against regulating research and development.\n- and I'm very much against regulations that would make open source AI illegal or difficult.", "likes": "", "reply": ""}
{"text": "I am extremely honored and grateful to be named the inaugural chair of the Courant Institute's Jacob T. Schwartz Chaired Professorship in Computer Science.\n\nJack Schwartz co-founded the NYU computer science department in the late 1960s, as a spin-off of the Courant Institute of…", "likes": "", "reply": ""}
{"text": "Anyone who thinks Auto-Regressive LLMs are getting close to human-level AI, or merely need to be scaled up to get there, *must* read this.\n\nAR-LLMs have very limited reasoning and planning abilities.\nThis will not be fixed by making them bigger and training them on more data.", "likes": "1.8K", "reply": "So my"}
{"text": "Which is why open research communities wins.", "likes": "313", "reply": "@eladgil"}
{"text": "Major fallacy here: \"closed frontier labs\" can't possibly stay simultaneously \"closed\" and \"frontier\" for very long.\nThey must either open up or fall behind.\nIn any case, they will lose whatever advance they think they have.\nWhy? Because people move around and ideas get around.", "likes": "294", "reply": "OS and open labs can scream & shout as they want into the void about their inventions & contributions but there is one objective fact: they have no absolute way to know if something already existed N years ago behind the wall of closed frontier labs."}
{"text": "Excellent piece by \n@Noahpinion\n on techno-optimism.\nSo many good points.\n\nLike Noah, I'm a humanist who subscribes to both Positive and Normative forms of Active Techno-Optimism.\n\nQuote: \"Techno-optimism is thus much more than an argument about the institutions of today or the…", "likes": "610", "reply": "The enemy of techno-optimism isn’t sustainability; it’s short-termism. \n\nHumanity should not build new things to pump up quarterly earnings; we should build them so that our descendants, in whatever form they come, will own the worlds and the stars. "}
{"text": "A reminder that people can disagree about important things but still be good friends.", "likes": "9K", "reply": ""}
{"text": "Chatting with \n@timoreilly\n today he said:\n  \"books are a user interface to knowledge.\"\nThat's what AI assistants are poised to become:\n  \"AI assistants will be a better user interface to knowledge.\"\n\nBut the same way books carry culture, AI will also become vehicles for culture.…", "likes": "", "reply": ""}
{"text": "Habitat 3.0 is released!\nVirtual environment with humanoid sims under human control, robots, realistic indoor environments, physics, ...\nPaper, open-source code, and datasets.", "likes": "443", "reply": "Announcing Habitat 3.0, simulating humanoid avatars and robots collaborating!\n\n- Humanoid sim: diverse skinned avatars\n- Human-in-the-loop control: mouse/keyboard or VR\n- Tasks: social navigation and rearrangement\n\nOver 1,000 steps per second on 1 GPU for large-scale learning!"}
{"text": "Yes, important to keep in mind that the very reason for the accelerated progress in AI is the fast and open exchange of ideas, publications, datasets, and code.\n\nWhoever embraces this open exchange can be part of the leading pack.\nWhoever cuts themselves from it inevitably falls…", "likes": "849", "reply": "Important to keep in mind that everyone in AI (including OAI) uses and benefits from open-source and wouldn’t be here without it. It’s the tide that lifts all boats! twitter.com/Mascobot/statu…"}
{"text": "Human feedback for open source LLMs needs to be crowd-sourced, Wikipedia style.\nIt is the only way for LLMs to become the repository of all human knowledge and cultures.\nWho wants to build the platform for this?", "likes": "2.3K", "reply": "Open LLMs need to get organized and co-ordinated about sharing human feedback. It's the weakest link with Open LLMs right now. They don't have 100m+ people giving feedback like in the case of OpenAI/Anthropic/Bard.\nThey can always progress with a Terms-of-Service arbitrage, but… twitter.com/bindureddy/sta…"}
{"text": "Collama: a quick hack from \n@varun_mathur\n \nhttps://collama.ai/varun/ethereum", "likes": "40", "reply": ""}
{"text": "Collama: a quick implementation of the idea of Wikipedia-style crowd-sourced fine-tuning for LLMs.", "likes": "577", "reply": " Wikipedia-style Community LLMs\n\ntl;dr: simple experiment showcasing why millions of Wikipedia-style community LLMs will one day provide a better user experience than the biggest closed AI startups for most use cases. it is hopeless to compete against \"us\".. "}
{"text": "A good counterpoint to the libertarian aspects of Marc \n@pmarca\n Andreessen's Techno-Optimist Manifesto.\n\nOne can believe in the intrinsic value of technological progress and economic growth, while not believing in libertarianism and knowing that markets need to be regulated to be… https://twitter.com/Jake_Browning00/status/1714758250829078885…", "likes": "576", "reply": ""}
{"text": "Jake rewrote his post. Here is the new one:", "likes": "42", "reply": "I hope that the good social technologies we've developed--and that Andreessen largely lumps into the \"enemies\"--will help limit some of the dangers of Techno-Optimism.\n \n(I don't know what happened to the first version of this post.) "}
{"text": "A new paper by \n@Jake_Browning00\n and me that just appeared in Artificial Intelligence.\nIt discusses the (in)validity of the \"propositional picture of semantic knowledge\" according to which all knowledge is expressible in language.\n\n\"Cognitive scientists and AI researchers now…", "likes": "470", "reply": "Why did we think the Winograd Schema Challenge would be a definitive test of common sense? And can there be a definitive test of common sense in language?\n\nA piece "}
{"text": "Repeat after me:  AI is not a weapon.\n\nWith or without open source AI, China is not far behind. Like many other countries, they want control over AI technology and must develop their own homegrown stack.", "likes": "1.3K", "reply": "Stanford's AI model openness ranking likely in reverse order of the competency of the model! Naive to ask private companies to disclose their secrets or investment will decline and we will help China. Would we disclose all details of the Manhattan Project?…"}
{"text": "Félicitations \n@julienmairal\n !", "likes": "26", "reply": " Découvrez les lauréats des "}
{"text": "Great work from FAIR-Paris in collaboration with ENS/PSL on reconstructing visual and speech inputs from magnetoencephalography signals.", "likes": "249", "reply": "Today we're sharing new research that brings us one step closer to real-time decoding of image perception from brain activity.\n\nUsing MEG, this AI system can decode the unfolding of visual representations in the brain with an unprecedented temporal resolution.\n\nMore details "}
{"text": "\"Democratized access [to open-source AI models] is a feature, not a bug.\"", "likes": "349", "reply": "I got to participate in a group discussion with leading policy thinkers/representatives/gov representatives on AI and open source regulation in the UK leading up to the summit today. Was a great experience and want to thank the people who put it together/invited me.\n\nThe…"}
{"text": "Knee-jerk panics about the deployment of new technology are nothing new.\nEven from scientists calling for bans.", "likes": "506", "reply": "The EU thought GMOs were an existential risk. Putting a moratorium on them, then massively over-regulating. \n\nThey’re only now walking some of it back. "}
{"text": "Good piece.\nOne doesn't have to agree with all the details to subscribe to the main tenets.", "likes": "456", "reply": "The Techno-Optimist Manifesto -- please read and Ask Me Anything! Post questions as replies to this xeet. "}
{"text": "Yay! Congrats \n@LerrelPinto\n ", "likes": "27", "reply": "I’m honored to receive the 2023 Packard Fellowship! With this funding, our lab "}
{"text": "Moral panic.", "likes": "440", "reply": "Congress discussing in 1993 how a pixelated Street Fighter game would cause violence and should be banned/regulated.\n\nThis was a big regulation topic a the time: twitter.com/PessimistsArc/…"}
{"text": "Exactly.", "likes": "181", "reply": "The AI models = nuclear weapons analogy is terrible for a lot of reasons, but most importantly it heavily misleads policy-makers. Nuke-inspired regulation won't prevent people from building powerful AIs, but it will protect tech companies from competition "}
{"text": "So am I.\nNuclear weapons are designed to wipe out entire cities.\nAI is designed to amplify human intelligence.\nOne destroys complexity.\nThe other increases it.\nTwo things could not be more different.", "likes": "1.3K", "reply": "I'm *really* tired of the AI models = nuclear weapons analogy "}
{"text": "As I pointed out before: AI alignment is going to be an iterative process of refinement.\nThere will be huge pressures to get rid of unaligned AI systems from customers and regulators.", "likes": "423", "reply": "Dog is highly aligned and human-interpretable intelligence. \n\nThis was achieved through selection pressure (unaligned dogs were put down).\n\nSame will happen via market selective pressures on AIs. They can and will be domesticated by the market. twitter.com/simongerman600…"}
{"text": "Discussions of AI safety need to be rational and based on science.", "likes": "290", "reply": "Things we need to get past in the AI safety discussion to make progress:\n- Circular arguments / tautologies : AGI definitionally being the feared end goal is a substance free position.\n- Bad/incomplete inductive arguments : I've yet to find an inductive step that has any rigor…"}
{"text": "Periodic reminder.", "likes": "2.5K", "reply": "Language is an imperfect, incomplete, and low-bandwidth serialization protocol for the internal data structures we call thoughts."}
{"text": "A more developed argument in this piece by \n@Jake_Browning00\n and me.", "likes": "106", "reply": ""}
{"text": "Open source AI models will soon become unbeatable.\nPeriod.", "likes": "3.4K", "reply": "The pace of open-source LLM innovation and research is breath-taking\n\nI suspect that open-source will soon become unbeatable for anyone except maybe OpenAI \n\nHere's why\n\n- Open-source community is "}
{"text": "The future will consist of\n-  a small number of open source inference code, \n- free pre-trained base models, and \n- crowd-sourced fine-tuned models, on top of which customized (possibly closed source) products will be built.", "likes": "", "reply": ""}
{"text": "To those who say:\n\"but closed source products have billions of investments behind them\"\nI reply:\nIn the mid-90a, Microsoft and Sun Microsystems battled to provide the software infrastructure of the internet, MS with WinNT+IIT+ASP+IE, Sun with Solaris+httpd+Java+Netscape.\nThey…", "likes": "", "reply": ""}
{"text": "The original version of this slide is from January 2016.", "likes": "393", "reply": "@infoxiao"}
{"text": "Do LLMs perform reasoning or approximate retrieval?\nThere is a continuum between the two, and Auto-Regressive LLMs are largely on the retrieval side.", "likes": "731", "reply": "People won't be so easily taken by \"LLM ingenuity\" if they stop thinking that they have a clue of what really is on the web.. "}
{"text": "Thanks, \n@alex_peys", "likes": "63", "reply": "lots of us are too busy working on this stuff to get in these debates on twitter, but yann is completely right here (just like he was with the cake thing, and the neural net thing, and and and) twitter.com/ylecun/status/…"}
{"text": "The cake thing.", "likes": "44", "reply": ""}
{"text": "Cool.", "likes": "214", "reply": "Introducing Universal Simulator (UniSim), an interactive simulator of the real world.\n\nInteractive website: "}
{"text": "Giving a keynote at MICCAI (26th International Conference on Medical Image Computing and Computer Assisted Intervention) in about 30 minutes.\n\nhttps://conferences.miccai.org/2023/en/KEYNOTES.html…", "likes": "176", "reply": ""}
{"text": "The heretofore silent majority of AI scientists and engineers who\n- do not believe in AI extinction scenarios or\n- believe we have agency in making AI powerful, reliable, and safe and\n- think the best way to do so is through open source AI platforms\nNEED TO SPEAK UP !", "likes": "2.1K", "reply": "@sriramk"}
{"text": "Even if you are not an Open Source Absolutist, it is hard to overestimate how much value OSS has added to the world.\nThis goes for AI as for everything else.", "likes": "864", "reply": "Be an Open Source Absolutist!\n\nIt is hard to overstate how much value Open Source Software has added to the world, and how broadly empowering it is.\n\nOperating systems, development tools, core libraries, and critical applications – a great many of the software tools used by the…"}
{"text": "Glad to be an advisor to this new initiative in AI for Science.", "likes": "539", "reply": "I'm super excited to share a new initiative I am a part of!\n\nAnnouncing: Polymathic AI "}
{"text": "The public in North America and the EU (not the rest of the world) is already scared enough about AI, even without mentioning the specter of existential risk.\n\nAs you know, the opinion of the *vast* majority of AI scientists and engineers (me included) is that the whole debate…", "likes": "684", "reply": "I think a big problem w getting the public to care about AI risk is that it’s just a *huge* emotional ask — for someone to really consider that there’s a solid chance that the whole world’s about to end. People will instinctively resist it tooth-and-nail."}
{"text": "A review of a new book by Scottish-born Princeton economist and Nobel Laureate Angus Deaton: \"Economics in America: An Immigrant Economist Explores the Land of Inequality\"\n\nQuote: \"The [US] political system  is more responsive to the needs of those who finance it than to its…", "likes": "", "reply": ""}
{"text": "It's not a controversial opinion.\nIt's just wrong.\n\nPeople who say a particular kind of music or painting is \"formless and meaningless\" simply do not understand its structure.\n\nThey simply cannot fathom how other people can understand and appreciate the structure they can't grok.", "likes": "1.4K", "reply": "Controversial opinion: Jazz is simply failed music. \n\nIt sounds like a child scribbling all over the page. Formless, meaningless, and unpleasant. Just a bunch of random noise that people trick themselves into liking, while they become numb to true musical quality in the process.…"}
{"text": "In case you're wondering: this is tenor saxophonist Dexter Gordon.", "likes": "", "reply": ""}
{"text": "Zing!", "likes": "209", "reply": "Yes. And it’s called saving lives. twitter.com/elonmusk/statu…"}
{"text": "France, obviously.\nDespite what many French residents falsely believe, inequalities have not substantially increased in France in the last 30 years.\nAnd inequalities decreased dramatically before that.\nIn the US, Reaganomics in 1980, with lower taxes on high incomes, caused…", "likes": "491", "reply": "Now, what country is this (red color)? It is a big and important country. (Answer in the next tweet.)"}
{"text": "There are about 5000 gods and divinities that humans have invented over millennia and are (still) worshiping.\nMonotheists believe in one of them and do not believe in the remaining 4999.\nThe difference between the number of gods monotheists and atheists do not believe in is a…", "likes": "", "reply": ""}
{"text": "If you value intelligence above all qualities, you're gonna have a *great* time.", "likes": "871", "reply": "if you value intelligence above all other human qualities, you’re gonna have a bad time"}
{"text": "Llama impact grants!", "likes": "110", "reply": "Applications for Llama Impact Grants are now open! \n\nToday until Nov 15, you can submit a proposal for using Llama 2 to address challenges across education, environment & open innovation for a chance to be awarded a $500K grant.\n\nDetails + application "}
{"text": "Mostly good advice.", "likes": "63", "reply": "Real rules to survive in New York:\n• Wear comfortable walking shoes.\n• Walk quickly, otherwise we'll despise you.\n• Walking 3 or 4 abreast is a hate crime.\n• Wear dark colors. You and the stains will blend in.\n• Pedestrian \"Don't Walk\" signs are only for decoration.\n•…"}
{"text": "Good point.", "likes": "62", "reply": "Magnetic fields carry angular momentum.\n\nConsider charges sitting along a circular wire. Apply a voltage and they start moving counter-clockwise. Theres now angular momentum.\n\nBut momentum is conserved, and started off zero - where's the equal but opposite amount? In the field."}
{"text": "Kaiser Permanente \n@aboutKP\n at the forefront of generative AI deployment in healthcare with Nabla's Copilot.", "likes": "60", "reply": ""}
{"text": "\"nerds are more often than not largely responsible for winning wars.\"\n\nLargely true, even if almost every war movie gives way more importance to heroism, sacrifice, and duty than to technology.", "likes": "503", "reply": "@JoeyMannarinoUS"}
{"text": "All physical laws are time reversible (under CPT symmetry).\nYet it doesn't look like the universe, or any sufficiently complex system, follows a reversible evolution.", "likes": "828", "reply": "What's the most mind-blowing fact you know about the universe? "}
{"text": "Some folks: \"Open source AI must be outlawed.\"\nOpen source AI startup community in Paris:", "likes": "1.5K", "reply": "If this is 7:40pm what happens at 10? "}
{"text": "Speech-from-MEG training code and data are available.", "likes": "47", "reply": "Our work on decoding is now published in Nature Machine Intelligence! We release the code to reproduce our results (and improve on them) based on public datasets (175 subjects, 160+ hours of brain recordings, EEG and MEG) "}
{"text": "Decoding speech from magnetoencephalography signals (MEG).\nFrom FAIR-Paris.", "likes": "210", "reply": "`Decoding speech perception from non-invasive brain recordings`, \nled by the one an only "}
{"text": "Given the prevalence of simultaneously clueless and misleading comments about various serious topics on X/Twitter (e.g. AI, vaccines,..), I feel the need for a new hashtag:\n#YHNIWYATA : You Have No Idea What You Are Talking About.\nOr perhaps the less polite #YHNIWTFYATA.", "likes": "", "reply": ""}
{"text": "Check out this thought-provoking piece by Léon Bottou and \n@bschoelkopf\n entitled \"Borges and AI\".", "likes": "71", "reply": "Léon and I have been hatching this out for over a year. Re-visiting Borges in this context profoundly impressed me. twitter.com/KyleCranmer/st…"}
{"text": "I do acknowledge risks.\n*BUT*\n1. Yes, open research and open source are the best ways to understand and mitigate them.\n2. AI is not something that just happens. *We* build it, *we* have agency in what it becomes. Hence *we* control the risks. It's not some sort of natural…", "likes": "681", "reply": "My followers might hate this idea, but I have to say it: There's a bunch of excellent LLM interpretability work coming out from AI safety folks (links below, from Max Tegmark, Dan Hendrycks, Owain Evans et al) studying open source models including Llama-2.  Without open source,…"}
{"text": "Selfied after talking with students in front of the Meta booth at ICCV - Paris", "likes": "867", "reply": ""}
{"text": "David Donoho says other fields should adopt the openness of ML/AI research that has made it progress so fast by enabling \"frictionless reproducibility\"\nAlso, we should ignore the fear-mongers.\nWe agree.", "likes": "225", "reply": "David Donoho nails it: "}
{"text": "Nicely consistent and variable generations from a world model.\nVideo generation is done in representation space.\nPixel generation is the final step, only useful for visualization and data generation.", "likes": "233", "reply": "What’s exciting about "}
{"text": "World models FTW.", "likes": "265", "reply": "Today we're announcing "}
{"text": "IBM, HuggingFace, and Mistral are in the green category.\nGoogle is turning red.\nInflection is a yellowish question mark.\n\nNow let's do governments....", "likes": "1.1K", "reply": "Funny how the more overvalued a company is, the more alarmist about AI."}
